Search.setIndex({"docnames": ["content/citation", "content/development", "content/gallery", "content/getting_started", "content/tutorials", "easy_transformer", "index", "model_properties_table", "modules", "setup", "transformer_lens", "transformer_lens.utilities", "typing_demo"], "filenames": ["content/citation.md", "content/development.md", "content/gallery.md", "content/getting_started.md", "content/tutorials.md", "easy_transformer.rst", "index.md", "model_properties_table.md", "modules.rst", "setup.rst", "transformer_lens.rst", "transformer_lens.utilities.rst", "typing_demo.rst"], "titles": ["Citation", "Local Development", "Gallery", "Getting Started", "Tutorials", "easy_transformer package", "TransformerLens", "Model Properties Table", "TransformerLens", "setup module", "transformer_lens package", "transformer_lens.utilities package", "typing_demo module"], "terms": {"pleas": [0, 1, 3], "cite": 0, "thi": [0, 1, 3, 4, 6, 10, 11], "librari": [0, 1, 2, 3, 4, 10], "misc": 0, "nandatransformerlens2022": 0, "titl": [0, 10], "transformerlen": [0, 1, 3, 4, 10], "author": 0, "nanda": [0, 10], "neel": [0, 4, 10], "url": 0, "http": [0, 3, 4, 10], "github": [0, 1, 3, 4, 10], "com": [0, 3, 4, 10], "neelnanda": [0, 3, 4, 10], "io": [0, 3, 4, 10], "year": 0, "2022": [0, 10], "i": [0, 3, 4, 6, 10, 11], "my": [0, 3, 4, 6, 10], "best": [0, 4, 10], "guess": 0, "how": [0, 3, 4, 6, 10], "softwar": 0, "work": [0, 2, 3, 4, 6, 10], "feel": [0, 6], "free": 0, "send": 0, "correct": [0, 10], "also": [0, 1, 4, 10, 11], "you": [0, 1, 3, 4, 6, 10], "re": [0, 3, 4, 10], "actual": [0, 10], "us": [0, 1, 2, 3, 4, 6, 10, 11], "your": [0, 1, 4, 10], "research": [0, 3, 4, 6], "d": [0, 7, 10], "love": 0, "chat": 0, "reach": [0, 10], "out": [0, 3, 4, 10], "neelnanda27": 0, "gmail": 0, "For": [1, 10], "one": [1, 3, 6, 10], "click": 1, "environ": 1, "project": [1, 4, 10], "includ": [1, 4, 10], "It": [1, 3, 4, 6, 10], "can": [1, 2, 3, 4, 6, 10], "v": [1, 10], "code": [1, 10], "codespac": 1, "poetri": 1, "packag": [1, 8], "manag": [1, 10], "instal": 1, "follow": [1, 6, 10], "virtual": 1, "config": [1, 8, 10], "virtualenv": 1, "true": [1, 10, 11], "dev": 1, "option": [1, 10, 11], "want": [1, 4, 10], "jupyt": 1, "lab": 1, "run": [1, 3, 6, 10], "pip": [1, 3], "jupyterlab": 1, "same": [1, 3, 10], "Then": [1, 10], "import": [1, 3, 6, 10], "transformer_len": [1, 3, 8], "If": [1, 3, 10, 11], "ad": [1, 4, 10], "featur": [1, 3, 4, 6, 10, 12], "add": [1, 6, 10], "unit": 1, "folder": 1, "check": [1, 3, 4, 10], "hasn": [1, 10], "t": [1, 6, 8, 10], "broken": [1, 10], "anyth": [1, 10], "major": 1, "exist": [1, 10], "pytest": 1, "root": 1, "directori": 1, "To": [1, 3, 10], "command": 1, "user": [2, 10], "contribut": [2, 10], "exampl": [2, 10], "being": [2, 10], "action": 2, "induct": [2, 10], "head": [2, 4, 10], "phase": 2, "chang": [2, 3, 10, 11], "replic": [2, 10], "A": [2, 10], "partial": [2, 10], "In": [2, 10], "context": [2, 10], "learn": [2, 3, 4, 6, 10], "from": [2, 3, 4, 6, 10], "connor": 2, "kissan": 2, "decis": [2, 3], "transform": [2, 3, 4, 10], "interpret": [2, 3, 4, 10], "set": [2, 10], "script": [2, 4], "train": [2, 4, 6, 8], "which": [2, 3, 4, 10], "len": 2, "view": 2, "intermedi": [2, 10], "activ": [2, 3, 4, 6, 10], "perform": [2, 4, 10], "attribut": [2, 4, 10], "ablat": 2, "write": [2, 3, 6, 10], "up": [2, 3, 10], "initi": [2, 10, 11], "found": [2, 10], "here": [2, 10], "main": [3, 4, 10], "demo": [3, 7, 10], "basic": [3, 4, 10], "see": [3, 4, 6, 10], "what": [3, 4, 6, 10], "exploratori": [3, 4, 6, 10], "analysi": [3, 4, 6, 10], "practic": [3, 4], "look": [3, 4, 10], "like": [3, 4, 6, 10], "notebook": [3, 4, 6, 10], "analys": [3, 4, 10], "indirect": [3, 4, 10], "object": [3, 4, 10], "identif": [3, 4, 10], "record": [3, 4], "myself": [3, 4], "do": [3, 4, 6, 10], "mechanist": [3, 4], "veri": [3, 4, 6, 10], "young": 3, "small": [3, 4, 6, 7, 10], "field": [3, 6, 10], "ar": [3, 4, 6, 10], "lot": [3, 4, 6, 10], "open": [3, 6, 10], "problem": [3, 6], "would": [3, 6, 10], "help": [3, 10], "try": [3, 10], "list": [3, 10], "concret": 3, "figur": 3, "where": [3, 10], "begin": [3, 10], "skill": 3, "kei": [3, 8, 10], "resourc": 3, "new": [3, 4, 10], "tutori": 3, "gpt": [3, 4, 6, 7, 10], "2": [3, 6, 7, 10], "scratch": 3, "an": [3, 4, 6, 10], "accompani": [3, 4], "templat": [3, 10], "yourself": [3, 10], "One": [3, 6], "signific": [3, 10], "design": [3, 6, 10], "made": [3, 10], "wa": [3, 10], "have": [3, 6, 10], "singl": [3, 10], "implement": [3, 10], "could": [3, 10], "support": [3, 4, 10], "rang": [3, 10], "subtli": [3, 10], "differ": [3, 10], "style": [3, 6, 10], "model": [3, 4, 10, 11], "ha": [3, 10], "upsid": 3, "just": [3, 10, 11], "arbitrari": [3, 10], "when": [3, 4, 10], "name": [3, 10], "hookedtransform": [3, 4, 8, 11], "from_pretrain": [3, 8, 10], "But": [3, 10], "downsid": 3, "py": [3, 10], "compon": [3, 8], "difficult": 3, "recommend": [3, 10], "clean": [3, 10], "minim": 3, "intern": [3, 6, 10], "architectur": 3, "significantli": [3, 10], "clearer": 3, "better": [3, 10], "document": [3, 10], "git": 3, "note": [3, 10], "known": [3, 6], "easytransform": [3, 6], "some": [3, 10], "break": [3, 10], "been": [3, 10], "sinc": [3, 10], "renam": 3, "need": [3, 6, 10], "old": 3, "version": [3, 4, 10], "legaci": [3, 10], "v1": 3, "patch": [4, 8], "colab": [4, 6], "googl": 4, "blob": 4, "ipynb": 4, "explain": 4, "techniqu": [4, 10], "causal": [4, 10], "intervent": 4, "identifi": [4, 10], "matter": [4, 10], "produc": [4, 10], "output": [4, 8, 10], "incomplet": 4, "gradient": [4, 10], "take": [4, 6, 10], "linear": [4, 10], "approxim": 4, "": [4, 6, 8, 10, 11], "good": [4, 6, 10], "individu": [4, 10], "attent": [4, 8, 10], "bad": [4, 10], "larg": [4, 6, 7, 10], "residu": [4, 10], "stream": [4, 10], "probabl": [4, 10], "place": [4, 10], "after": [4, 6, 10], "demonstr": 4, "focus": 4, "less": [4, 10], "rigor": 4, "more": [4, 6, 10], "get": [4, 6, 10], "grasp": 4, "go": 4, "quickli": 4, "logit": [4, 8, 10], "steal": 4, "liber": [4, 10], "grokk": 4, "phenomenon": 4, "memoris": 4, "data": [4, 10], "minimis": 4, "loss": [4, 8, 10], "longer": 4, "generalis": 4, "lead": [4, 10], "sharp": 4, "decreas": [4, 10], "test": [4, 8, 10, 12], "well": [4, 10], "show": [4, 6, 10], "task": [4, 10], "modular": 4, "addit": [4, 10], "verifi": 4, "grok": 4, "The": [4, 6, 10, 11], "light": 4, "explan": [4, 10], "so": [4, 10], "ll": [4, 10], "pair": [4, 8, 10], "video": 4, "seri": [4, 10], "paper": [4, 10], "base": [4, 10, 11], "detector": 4, "automat": [4, 10], "detect": [4, 10], "sever": [4, 10], "common": [4, 10], "type": [4, 10, 11], "creat": [4, 10], "own": 4, "custom": [4, 10], "algorithm": [4, 6, 10], "find": [4, 10], "interact": 4, "neuroscop": 4, "hacki": [4, 10], "bug": [4, 10], "web": 4, "visualis": 4, "even": [4, 6, 10], "profession": 4, "front": 4, "end": [4, 10], "develop": 4, "visual": 4, "neuron": [4, 10], "text": [4, 10], "dynam": 4, "updat": [4, 10], "edit": [4, 6, 10], "llama": 4, "convert": [4, 10], "meta": [4, 10], "7b": [4, 7], "paramet": [4, 10, 11], "now": [4, 10], "until": [4, 10], "multi": [4, 10], "gpu": [4, 10], "great": [4, 6], "avail": [4, 10], "access": [4, 10], "gener": [4, 8, 10], "should": [4, 10], "know": [4, 10], "about": [4, 6, 10], "No": 4, "posit": [4, 10], "experi": [4, 6, 10], "real": [4, 6], "time": [4, 10], "embed": [4, 10], "predict": [4, 10], "previou": [4, 10], "token": [4, 10], "make": [4, 6, 10], "othello": 4, "port": 4, "weight": [4, 6, 10], "excel": [4, 6], "emerg": 4, "world": [4, 6], "represent": 4, "sequenc": [4, 10], "investig": [4, 10], "worth": [4, 10], "read": 4, "interest": [4, 10], "topic": 4, "svd": [4, 8, 10], "conjectur": 4, "post": [4, 10], "singular": [4, 10], "valu": [4, 6, 8, 10], "decomposit": [4, 10], "matric": [4, 10], "surprisingli": 4, "reproduc": [4, 10], "further": [4, 10], "tracr": 4, "cool": 4, "deepmind": 4, "tool": [4, 6], "compil": 4, "written": 4, "program": [4, 6], "rasp": 4, "jax": 4, "form": [4, 10], "pytorch": [4, 10], "formerli": 6, "goal": 6, "revers": [6, 10], "engin": 6, "dure": [6, 10], "its": [6, 10], "fact": 6, "todai": 6, "we": [6, 10], "comput": [6, 10], "essenti": [6, 10], "speak": 6, "english": [6, 10], "human": 6, "level": [6, 10], "3": [6, 7, 10], "palm": 6, "etc": [6, 10], "yet": [6, 10], "idea": [6, 10], "thei": [6, 10], "nor": 6, "ourselv": [6, 10], "offend": 6, "me": [6, 10], "greatli": 6, "solv": [6, 10], "let": [6, 10], "load": [6, 10], "sourc": [6, 10], "expos": [6, 10], "cach": [6, 10], "ani": [6, 10], "function": [6, 10, 11], "remov": [6, 10], "replac": [6, 10], "core": 6, "principl": 6, "ve": [6, 10], "enabl": [6, 10], "most": [6, 10], "fun": 6, "part": [6, 10], "compar": [6, 10], "normal": [6, 10], "ml": 6, "extrem": 6, "short": [6, 10], "feedback": [6, 10], "loop": [6, 10], "point": [6, 10], "keep": [6, 10], "gap": 6, "between": [6, 10], "result": [6, 10], "possibl": [6, 10], "easi": [6, 10], "plai": 6, "enter": [6, 10], "flow": 6, "state": [6, 10], "aim": 6, "easier": [6, 10], "hopefulli": [6, 10], "transfer": 6, "anthrop": 6, "team": 6, "wrote": 6, "becaus": [6, 10], "left": [6, 10], "tri": [6, 10], "independ": 6, "got": [6, 10], "frustrat": 6, "There": [6, 10], "infrastructur": [6, 10], "huggingfac": [6, 10], "deepspe": 6, "littl": 6, "dig": 6, "don": [6, 10], "industri": 6, "org": [6, 10], "thing": [6, 10], "ton": [6, 10], "were": [6, 10], "heavili": 6, "inspir": [6, 10], "interfac": [6, 10], "garcon": [6, 10], "credit": 6, "nelson": 6, "elhag": 6, "chri": 6, "olah": 6, "build": [6, 10], "n_param": [7, 8, 10], "n_layer": [7, 8, 10, 11], "d_model": [7, 8, 10], "n_head": [7, 8, 10], "act_fn": [7, 8, 10], "n_ctx": [7, 8, 10], "d_vocab": [7, 8, 10], "d_head": [7, 8, 10], "d_mlp": [7, 8, 10], "gpt2": [7, 10], "85m": 7, "12": [7, 10], "768": [7, 10], "gelu": [7, 10], "1024": [7, 10], "50257": [7, 10], "64": [7, 10], "3072": [7, 10], "medium": 7, "302m": 7, "24": [7, 10], "16": 7, "4096": 7, "708m": 7, "36": 7, "1280": 7, "20": [7, 10], "5120": 7, "xl": 7, "1": [7, 10], "5b": 7, "48": 7, "1600": 7, "25": 7, "6400": 7, "distillgpt2": 7, "42m": 7, "6": [7, 10], "opt": [7, 10], "125m": 7, "relu": [7, 10], "2048": 7, "50272": 7, "3b": 7, "2b": 7, "32": 7, "8192": 7, "2560": 7, "80": 7, "10240": 7, "4b": 7, "128": 7, "16384": 7, "13b": 7, "40": 7, "20480": 7, "30b": 7, "7168": 7, "56": 7, "28672": 7, "66b": 7, "65b": 7, "9216": 7, "72": 7, "36864": 7, "neo": 7, "j": [7, 10], "6b": 7, "5": [7, 10], "28": 7, "50400": 7, "256": 7, "neox": [7, 10], "20b": 7, "44": 7, "6144": 7, "50432": 7, "96": 7, "24576": 7, "stanford": [7, 10], "b": [7, 10], "c": 7, "e": [7, 10], "pythia": 7, "70m": 7, "19m": 7, "512": 7, "8": [7, 10], "50304": 7, "160m": 7, "410m": 7, "1b": 7, "805m": 7, "8b": 7, "9b": 7, "12b": 7, "11b": 7, "50688": 7, "dedup": 7, "solu": [7, 8, 10], "1l": 7, "pile": [7, 10], "13m": 7, "50278": 7, "2l": [7, 10], "736": 7, "11": 7, "2944": 7, "4l": 7, "4": [7, 10], "6l": 7, "8l": 7, "101m": 7, "10l": 7, "197m": 7, "10": [7, 10], "12l": 7, "340m": 7, "1536": 7, "1m": 7, "48262": 7, "3m": 7, "3l": 7, "9": [7, 10], "4m": 7, "attn": [7, 10], "onli": [7, 10], "0m": 7, "attn_onli": [7, 8, 10], "2m": 7, "50277": 7, "wiki": [7, 10], "easy_transform": 8, "modul": 8, "content": 8, "setup": [8, 10], "subpackag": 8, "util": 8, "submodul": 8, "devic": [8, 10], "activationcach": 8, "accumulated_resid": [8, 10], "apply_ln_to_stack": [8, 10], "apply_slice_to_batch_dim": [8, 10], "compute_head_result": [8, 10], "decompose_resid": [8, 10], "get_full_resid_decomposit": [8, 10], "get_neuron_result": [8, 10], "item": [8, 10], "logit_attr": [8, 10], "remove_batch_dim": [8, 10], "stack_activ": [8, 10], "stack_head_result": [8, 10], "stack_neuron_result": [8, 10], "toggle_autodiff": [8, 10], "factoredmatrix": 8, "ab": [8, 10], "ba": [8, 10], "u": [8, 10], "vh": [8, 10], "collapse_l": [8, 10], "collapse_r": [8, 10], "eigenvalu": [8, 10], "get_corn": [8, 10], "make_even": [8, 10], "ndim": [8, 10], "norm": [8, 10], "unsqueez": [8, 10], "hookedencod": [8, 11], "ov": [8, 10], "qk": [8, 10], "w_e": [8, 10], "w_e_po": [8, 10], "w_k": [8, 10], "w_o": [8, 10], "w_q": [8, 10], "w_u": [8, 10], "w_v": [8, 10], "w_in": [8, 10], "w_out": [8, 10], "w_po": [8, 10], "all_head_label": [8, 10], "b_k": [8, 10], "b_o": [8, 10], "b_q": [8, 10], "b_u": [8, 10], "b_v": [8, 10], "b_in": [8, 10], "b_out": [8, 10], "cpu": [8, 10], "cuda": [8, 10], "forward": [8, 10], "run_with_cach": [8, 10], "accumulated_bia": [8, 10], "all_composition_scor": [8, 10], "center_unemb": [8, 10], "center_writing_weight": [8, 10], "check_hooks_to_add": [8, 10], "fold_layer_norm": [8, 10], "fold_value_bias": [8, 10], "from_pretrained_no_process": [8, 10], "get_token_posit": [8, 10], "init_weight": [8, 10], "load_and_process_state_dict": [8, 10], "load_sample_training_dataset": [8, 10], "loss_fn": [8, 10], "move_model_modules_to_devic": [8, 10], "process_weights_": [8, 10], "refactor_factored_attn_matric": [8, 10], "sample_datapoint": [8, 10], "set_token": [8, 10], "set_use_attn_in": [8, 10], "set_use_attn_result": [8, 10], "set_use_hook_mlp_in": [8, 10], "set_use_split_qkv_input": [8, 10], "set_use_split_qkv_normalized_input": [8, 10], "to_single_str_token": [8, 10], "to_single_token": [8, 10], "to_str_token": [8, 10], "to_str": [8, 10], "to_token": [8, 10], "tokens_to_residual_direct": [8, 10], "hookedtransformerconfig": [8, 11], "attention_dir": [8, 10], "attn_typ": [8, 10], "checkpoint_index": [8, 10], "checkpoint_label_typ": [8, 10], "checkpoint_valu": [8, 10], "d_vocab_out": [8, 10], "ep": [8, 10], "final_rm": [8, 10], "from_checkpoint": [8, 10], "from_dict": [8, 10], "gated_mlp": [8, 10], "init_mod": [8, 10], "initializer_rang": [8, 10], "model_nam": [8, 10], "n_devic": [8, 10, 11], "normalization_typ": [8, 10], "original_architectur": [8, 10], "parallel_attn_mlp": [8, 10], "positional_embedding_typ": [8, 10], "rotary_dim": [8, 10], "scale_attn_by_inverse_layer_idx": [8, 10], "seed": [8, 10], "set_seed_everywher": [8, 10], "to_dict": [8, 10], "tokenizer_nam": [8, 10], "use_attn_in": [8, 10], "use_attn_result": [8, 10], "use_attn_scal": [8, 10], "use_hook_mlp_in": [8, 10], "use_hook_token": [8, 10], "use_local_attn": [8, 10], "use_split_qkv_input": [8, 10], "use_split_qkv_normalized_input": [8, 10], "window_s": [8, 10], "apply_causal_mask": [8, 10], "apply_rotari": [8, 10], "calculate_sin_cos_rotari": [8, 10], "rotary_rotate_qk": [8, 10], "rotate_every_two": [8, 10], "bertblock": [8, 10], "bertemb": [8, 10], "bertmlmhead": [8, 10], "emb": [8, 10], "gatedmlp": [8, 10], "layernorm": [8, 10], "layernormpr": [8, 10], "mlp": [8, 10], "posemb": [8, 10], "rmsnorm": [8, 10], "rmsnormpr": [8, 10], "tokentypeemb": [8, 10], "transformerblock": [8, 10], "unemb": [8, 10], "eval": 8, "ioidataset": [8, 10], "get_default_nam": [8, 10], "get_default_noun": [8, 10], "get_default_templ": [8, 10], "get_sampl": [8, 10], "evalu": [8, 10], "evaluate_on_dataset": [8, 10], "induction_loss": [8, 10], "ioi_ev": [8, 10], "make_code_data_load": [8, 10], "make_owt_data_load": [8, 10], "make_pile_data_load": [8, 10], "make_wiki_data_load": [8, 10], "sanity_check": [8, 10], "head_detector": 8, "compute_head_attention_similarity_scor": [8, 10], "detect_head": [8, 10], "get_duplicate_token_head_detection_pattern": [8, 10], "get_induction_head_detection_pattern": [8, 10], "get_previous_token_head_detection_pattern": [8, 10], "get_supported_head": [8, 10], "hook_point": 8, "hookpoint": [8, 10], "add_hook": [8, 10], "add_perma_hook": [8, 10], "clear_context": [8, 10], "layer": [8, 10, 11], "remove_hook": [8, 10], "hookedrootmodul": [8, 10], "add_caching_hook": [8, 10], "cache_al": [8, 10], "cache_som": [8, 10], "check_and_add_hook": [8, 10], "get_caching_hook": [8, 10], "hook": [8, 10], "remove_all_hook_fn": [8, 10], "reset_hook": [8, 10], "run_with_hook": [8, 10], "lenshandl": [8, 10], "is_perman": [8, 10], "context_level": [8, 10], "loading_from_pretrain": 8, "debug": [8, 10], "init_rang": [8, 10], "layer_norm_ep": [8, 10], "get_checkpoint_label": [8, 10], "get_num_params_of_pretrain": [8, 10], "get_pretrained_model_config": [8, 10], "make_doc": 8, "past_key_value_cach": 8, "hookedtransformerkeyvaluecach": [8, 10], "entri": [8, 10], "init_cach": [8, 10], "hookedtransformerkeyvaluecacheentri": [8, 10], "append": [8, 10], "init_cache_entri": [8, 10], "past_kei": [8, 10], "past_valu": [8, 10], "generic_activation_patch": [8, 10], "get_act_patch_attn_head_all_pos_everi": [8, 10], "get_act_patch_attn_head_by_pos_everi": [8, 10], "get_act_patch_attn_head_k_all_po": [8, 10], "get_act_patch_attn_head_k_by_po": [8, 10], "get_act_patch_attn_head_out_all_po": [8, 10], "get_act_patch_attn_head_out_by_po": [8, 10], "get_act_patch_attn_head_pattern_all_po": [8, 10], "get_act_patch_attn_head_pattern_by_po": [8, 10], "get_act_patch_attn_head_pattern_dest_src_po": [8, 10], "get_act_patch_attn_head_q_all_po": [8, 10], "get_act_patch_attn_head_q_by_po": [8, 10], "get_act_patch_attn_head_v_all_po": [8, 10], "get_act_patch_attn_head_v_by_po": [8, 10], "get_act_patch_attn_out": [8, 10], "get_act_patch_block_everi": [8, 10], "get_act_patch_mlp_out": [8, 10], "get_act_patch_resid_mid": [8, 10], "get_act_patch_resid_pr": [8, 10], "layer_head_dest_src_pos_pattern_patch_sett": [8, 10], "layer_head_pattern_patch_sett": [8, 10], "layer_head_pos_pattern_patch_sett": [8, 10], "layer_head_vector_patch_sett": [8, 10], "layer_pos_head_vector_patch_sett": [8, 10], "layer_pos_patch_sett": [8, 10], "hookedtransformertrainconfig": [8, 10], "batch_siz": [8, 10], "lr": [8, 10], "max_grad_norm": [8, 10], "max_step": [8, 10], "momentum": [8, 10], "num_epoch": [8, 10], "optimizer_nam": [8, 10], "print_everi": [8, 10], "save_dir": [8, 10], "save_everi": [8, 10], "wandb": [8, 10], "wandb_project_nam": [8, 10], "warmup_step": [8, 10], "weight_decai": [8, 10], "slice": [8, 10], "appli": [8, 10], "indic": [8, 10], "sliceinput": [8, 10], "composition_scor": [8, 10], "download_file_from_hf": [8, 10], "gelu_fast": [8, 10], "gelu_new": [8, 10], "get_act_nam": [8, 10], "get_dataset": [8, 10], "is_lower_triangular": [8, 10], "is_squar": [8, 10], "keep_single_column": [8, 10], "lm_accuraci": [8, 10], "lm_cross_entropy_loss": [8, 10], "print_gpu_mem": [8, 10], "sample_logit": [8, 10], "test_prompt": [8, 10], "to_numpi": [8, 10], "tokenize_and_concaten": [8, 10], "transpos": [8, 10], "typing_demo": 8, "test2": [8, 12], "test3": [8, 12], "test4": [8, 12], "get_device_for_block_index": [10, 11], "move_to_and_update_config": [10, 11], "class": 10, "cache_dict": 10, "dict": 10, "str": [10, 11], "tensor": [10, 12], "has_batch_dim": 10, "bool": 10, "wrapper": [10, 11], "around": [10, 11], "dictionari": 10, "varieti": 10, "helper": 10, "specif": 10, "process": 10, "method": 10, "while": 10, "other": 10, "all": 10, "without": 10, "warn": 10, "biggest": 10, "footgun": 10, "track": 10, "index": [10, 11], "dimens": 10, "number": [10, 11], "each": 10, "kind": 10, "vector": 10, "q": 10, "k": 10, "z": 10, "shape": 10, "batch": [10, 12], "po": 10, "head_index": 10, "pattern": 10, "softmax": 10, "attn_scor": 10, "pre": 10, "query_po": 10, "key_po": 10, "mid": 10, "solu_ln": 10, "resid_pr": 10, "resid_mid": 10, "resid_post": 10, "attn_out": 10, "mlp_out": 10, "pos_emb": 10, "ln": 10, "lnpre": 10, "scale": 10, "sometim": 10, "miss": 10, "robust": 10, "think": 10, "everyth": 10, "easili": 10, "wrong": 10, "annot": 10, "layers_cov": 10, "queri": 10, "stack": 10, "batch_and_pos_dim": 10, "default": 10, "int": [10, 11], "none": [10, 11], "incl_mid": 10, "fals": 10, "apply_ln": 10, "pos_slic": 10, "union": [10, 11], "tupl": 10, "ndarrai": 10, "mlp_input": 10, "return_label": 10, "float": [10, 12], "return": [10, 11], "accumul": 10, "given": [10, 11], "ie": 10, "input": 10, "thought": 10, "gradual": 10, "exclud": 10, "mean": 10, "final": 10, "immedi": 10, "taken": 10, "give": 10, "l": 10, "whether": 10, "current": 10, "rather": 10, "than": 10, "noth": 10, "label": 10, "graph": 10, "num_compon": 10, "residual_stack": 10, "batch_slic": 10, "eg": 10, "treat": 10, "them": 10, "factor": 10, "simul": 10, "global": 10, "across": [10, 11], "entir": 10, "element": 10, "why": 10, "doe": 10, "unchang": 10, "torch": [10, 11], "whose": 10, "trail": 10, "assum": 10, "store": 10, "hook_scal": 10, "mai": 10, "0": 10, "map": 10, "case": 10, "ln2": 10, "ln1": 10, "must": 10, "ln_final": 10, "over": 10, "full": 10, "alreadi": 10, "detail": 10, "amount": 10, "sum": 10, "plu": 10, "intend": 10, "forget": 10, "mode": 10, "typing_extens": 10, "liter": 10, "incl_emb": 10, "decompos": 10, "behaviour": 10, "incl": 10, "expand_neuron": 10, "bias": 10, "down": 10, "expand": 10, "everi": 10, "neuron_slic": 10, "num_neuron": 10, "much": 10, "subset": 10, "specifi": [10, 11], "expens": 10, "space": 10, "cheap": 10, "axi": 10, "incorrect_token": 10, "provid": [10, 11], "activation_nam": 10, "sublayer_typ": 10, "wai": 10, "exactli": 10, "strictli": 10, "befor": 10, "sub": 10, "pass": [10, 11], "infer": 10, "incl_remaind": 10, "term": 10, "rest": 10, "length": 10, "x": [10, 12], "einop": 10, "notat": 10, "l0h0": 10, "l0n0": 10, "super": 10, "memori": 10, "move_model": 10, "move": 10, "mostli": 10, "finish": 10, "save": 10, "matmul": 10, "slower": 10, "unless": 10, "autodiff": 10, "turn": 10, "off": 10, "pretti": 10, "danger": 10, "abil": 10, "complet": 10, "bunch": 10, "error": 10, "realis": 10, "consum": 10, "downstream": 10, "delet": 10, "stick": 10, "often": 10, "troubl": 10, "mess": 10, "inference_mod": 10, "decor": 10, "achiev": 10, "similar": 10, "effect": 10, "ldim": 10, "mdim": 10, "rdim": 10, "repres": 10, "low": 10, "rank": 10, "matrix": 10, "product": 10, "two": 10, "effici": 10, "calcul": 10, "properti": 10, "leading_dim": 10, "sens": 10, "collaps": 10, "side": 10, "orthogon": 10, "self": 10, "analog": 10, "apart": 10, "zero": 10, "bav": 10, "kv": 10, "abav": 10, "kav": 10, "av": 10, "eigenvector": 10, "sqrt": 10, "diag": 10, "equival": 10, "factoris": 10, "half": 10, "row": 10, "col": 10, "frobeniu": 10, "squar": 10, "m": 10, "st": 10, "obviou": 10, "cfg": [10, 11], "move_to_devic": 10, "kwarg": 10, "bert": 10, "encod": 10, "inherit": 10, "limit": 10, "mvp": 10, "mask": 10, "languag": 10, "mlm": 10, "next": 10, "sentenc": 10, "nsp": 10, "dropout": 10, "inconsist": 10, "fine": 10, "tune": 10, "pretrain": 10, "via": 10, "few": 10, "might": 10, "preprocess": 10, "g": 10, "fold": 10, "accept": 10, "string": [10, 11], "conveni": 10, "concaten": 10, "overcomplet": 10, "basi": 10, "circuit": 10, "unembed": 10, "absolut": 10, "buffer": 10, "modifi": 10, "associ": 10, "call": 10, "construct": 10, "optim": 10, "live": 10, "copi": 10, "return_typ": 10, "token_type_id": 10, "one_zero_attention_mask": 10, "binari": 10, "id": 10, "belong": 10, "cl": 10, "sep": 10, "typic": 10, "sequence_length": 10, "attend": 10, "ignor": 10, "primarili": 10, "pad": 10, "variabl": 10, "instanc": 10, "shorter": 10, "right": 10, "classmethod": 10, "hf_model": 10, "from_pretrained_kwarg": 10, "bertformaskedlm": 10, "unlik": 10, "model_arg": 10, "return_cache_object": 10, "otherwis": 10, "directli": 10, "device_or_dtyp": [10, 11], "dtype": [10, 11], "print_detail": [10, 11], "cast": 10, "non_block": 10, "memory_format": 10, "channels_last": 10, "Its": 10, "signatur": 10, "complex": 10, "integr": 10, "asynchron": 10, "respect": 10, "host": 10, "pin": 10, "below": 10, "desir": 10, "format": 10, "4d": 10, "keyword": 10, "argument": 10, "xdoctest": 10, "ignore_w": 10, "non": 10, "determinist": 10, "nn": 10, "contain": 10, "1913": 10, "3420": 10, "5113": 10, "2325": 10, "doubl": 10, "in_featur": 10, "out_featur": 10, "bia": 10, "float64": 10, "requir": 10, "env": 10, "torch_doctest_cuda1": 10, "gpu1": 10, "1914": 10, "5112": 10, "2324": 10, "float16": 10, "cdoubl": 10, "3741": 10, "2382": 10, "5593": 10, "4443": 10, "complex128": 10, "ones": 10, "6122": 10, "1150": 10, "instanti": 10, "randomli": 10, "__init__": 10, "include_mlp_bias": 10, "layers_accumulated_ov": 10, "composit": 10, "score": 10, "l1": 10, "h1": 10, "l2": 10, "h2": 10, "upper": 10, "triangular": 10, "first": 10, "third": 10, "ax": 10, "pub": 10, "2021": 10, "framework": 10, "html": 10, "20abov": 10, "20diagram": 10, "20show": 10, "20q": 10, "2d": 10, "2c": 10, "20k": 10, "20and": 10, "20v": 10, "2dcomposit": 10, "three": 10, "metric": 10, "state_dict": 10, "center": 10, "done": 10, "subtract": 10, "themselv": 10, "As": 10, "translat": 10, "invari": 10, "log": 10, "prob": 10, "slightli": 10, "understand": 10, "misl": 10, "someth": 10, "hook_point_nam": 10, "dir": 10, "fwd": 10, "prepend": 10, "overrid": 10, "consist": 10, "neighbour": 10, "further_com": 10, "md": 10, "alwai": 10, "constant": 10, "togeth": 10, "harder": 10, "doesn": 10, "formal": 10, "b_o_new": 10, "b_o_origin": 10, "sum_head": 10, "b_v_head": 10, "w_o_head": 10, "loss_per_token": 10, "prepend_bo": 10, "stop_at_lay": 10, "past_kv_cach": 10, "both": 10, "either": 10, "flag": 10, "cross": 10, "entropi": 10, "per": 10, "averag": 10, "scalar": 10, "bo": 10, "explicitli": 10, "accordingli": 10, "lose": 10, "inform": 10, "empir": 10, "seem": 10, "stop": 10, "exclus": 10, "block": 10, "neg": 10, "standard": 10, "fold_ln": 10, "autoregress": 10, "gptneo": 10, "gptj": 10, "toi": 10, "checkpoint": 10, "crfm": 10, "These": 10, "determin": [10, 11], "1000": 10, "step": 10, "neither": 10, "official_model_nam": 10, "alia": 10, "subsequ": 10, "due": 10, "affect": 10, "automodelforcausallm": 10, "recreat": 10, "onto": 10, "By": 10, "els": 10, "split": 10, "greater": 10, "cannot": 10, "multipl": [10, 11], "cache_dir": 10, "torch_dtyp": 10, "compat": 10, "especi": 10, "boolean": 10, "relat": 10, "simplifi": 10, "refer": 10, "max_new_token": 10, "stop_at_eo": 10, "eos_token_id": 10, "do_sampl": 10, "top_k": 10, "top_p": 10, "temperatur": 10, "freq_penalti": 10, "num_return_sequ": 10, "use_past_kv_cach": 10, "verbos": 10, "pos_plus_new_token": 10, "sampl": 10, "eos_token": 10, "avoid": 10, "fiddl": 10, "rag": 10, "eot": 10, "throw": 10, "awai": 10, "messi": 10, "instead": 10, "size": 10, "maximum": 10, "distribut": [10, 11], "greedi": 10, "search": 10, "max": 10, "mass": 10, "top": 10, "cumul": 10, "higher": 10, "random": 10, "temp": 10, "inf": 10, "uniform": 10, "frequenc": 10, "penalti": 10, "penalis": 10, "speed": 10, "bos_token_id": 10, "irrelev": 10, "whatev": 10, "tqdm": 10, "progress": 10, "bar": 10, "single_token": 10, "rais": 10, "present": 10, "gotcha": 10, "Be": 10, "care": 10, "start": 10, "prompt": 10, "weird": 10, "carefulli": 10, "correspond": 10, "dummi": 10, "match": 10, "last": 10, "std": 10, "02": 10, "roughli": 10, "scheme": 10, "truncat": 10, "halv": 10, "empti": 10, "bulk": 10, "w_": 10, "ensur": 10, "NOT": 10, "far": 10, "tell": 10, "date": 10, "gotten": 10, "round": 10, "issu": 10, "18182": 10, "transformerencod": 10, "exact": 10, "72253": 10, "mup": 10, "haven": 10, "those": 10, "arxiv": 10, "2203": 10, "03466": 10, "relev": 10, "special": 10, "redwood": 10, "10k": 10, "dataset": 10, "appropri": 10, "info": 10, "download": 10, "locat": 10, "openwebtext": 10, "link": 10, "karma": 10, "reddit": 10, "hard": 10, "cover": 10, "imperfectli": 10, "suppli": 10, "valid": 10, "per_token": 10, "allow": 10, "cleaner": 10, "experiment": 10, "argu": 10, "mathemat": 10, "somewhat": 10, "w_qk": 10, "w_ov": 10, "mani": 10, "attempt": 10, "column": 10, "rotat": 10, "nth": 10, "formula": 10, "r": 10, "refactor": 10, "diagon": 10, "asymmetri": 10, "fiddli": 10, "deal": 10, "preserv": 10, "along": 10, "too": 10, "bilinear": 10, "y": 10, "fairli": 10, "dimension": 10, "coordin": 10, "separ": 10, "implicitli": 10, "manual": 10, "choic": 10, "pretrainedtoken": 10, "toggl": 10, "burn": 10, "through": [10, 11], "int_token": 10, "uncertain": 10, "weirdli": 10, "sure": 10, "gotcha2": 10, "depend": 10, "preced": 10, "letter": 10, "capit": 10, "shoot": 10, "foot": 10, "gotcha3": 10, "exce": 10, "str_token": 10, "numpi": 10, "arrai": 10, "long": 10, "window": 10, "dot": 10, "mislead": 10, "incorrect": 10, "direct": 10, "integ": 10, "residual_direct": 10, "namedtupl": 10, "1e": 10, "05": 10, "configur": [10, 11], "AND": 10, "feedforward": 10, "network": 10, "vocabulari": 10, "vocab": 10, "lowercas": 10, "silu": 10, "epsilon": 10, "THEN": 10, "intens": 10, "qkv": 10, "famili": 10, "local": 10, "destin": 10, "certain": 10, "distanc": 10, "back": 10, "weight_init_mod": 10, "pipelin": 10, "parallel": 10, "respons": 10, "aka": 10, "unidirect": 10, "bidirect": 10, "python": 10, "deviat": 10, "initialis": 10, "layer_id": 10, "mistral": 10, "numer": 10, "stabil": 10, "fp16": 10, "rotari": 10, "describ": 10, "blog": 10, "eleuth": 10, "ai": 10, "shortform": 10, "res_stream": 10, "sinusoid": 10, "dumb": 10, "origin": 10, "equal": 10, "mainli": 10, "curs": 10, "hidden": 10, "law": 10, "pdf": 10, "2001": 10, "08361": 10, "meaning": 10, "Will": 10, "interven": 10, "config_dict": 10, "defin": 10, "pure": 10, "glossari": 10, "order": 10, "multipli": 10, "sorri": 10, "lru_cach": 10, "sai": 10, "underli": 10, "destination_residu": 10, "destination_po": 10, "source_po": 10, "pos_plus_past_kv_pos_offset": 10, "past_kv_pos_offset": 10, "10000": 10, "sine": 10, "cosin": 10, "wave": 10, "inexplic": 10, "reason": 10, "adjac": 10, "n": 10, "clue": 10, "resolv": 10, "query_input": 10, "key_input": 10, "value_input": 10, "past_kv_cache_entri": 10, "additive_attention_mask": 10, "shortformer_pos_emb": 10, "past": 10, "x0": 10, "x1": 10, "except": 10, "overridden": 10, "subclass": 10, "although": 10, "recip": 10, "within": 10, "afterward": 10, "former": 10, "regist": 10, "latter": 10, "silent": 10, "input_id": 10, "purpos": 10, "resid": 10, "unus": 10, "broadcast": 10, "dim": 10, "1810": 10, "04805": 10, "block_index": 10, "positional_embeddings_typ": 10, "_description_": 10, "_type_": 10, "file": 10, "rough": 10, "expect": 10, "properli": 10, "cheapli": 10, "baselin": 10, "noun": 10, "num_sampl": 10, "symmetr": 10, "2211": 10, "00593": 10, "print": 10, "100": 10, "655226745605469": 10, "accuraci": 10, "met": 10, "gave": 10, "alic": 10, "bob": 10, "charli": 10, "ball": 10, "book": 10, "7498160457611083": 10, "static": 10, "data_load": 10, "subseq_len": 10, "384": 10, "repeat": 10, "twice": 10, "measur": 10, "second": 10, "longtensor": 10, "codeparrot": 10, "dump": 10, "lower": 10, "presum": 10, "natur": 10, "corpu": 10, "eleutherai": 10, "22": 10, "academ": 10, "internet": 10, "wikitext": 10, "wikipedia": 10, "articl": 10, "larger": 10, "realli": 10, "anyon": 10, "bother": 10, "quarantin": 10, "nowadai": 10, "leakag": 10, "though": 10, "believ": 10, "feed": 10, "paragraph": 10, "zoom": 10, "quick": 10, "saniti": 10, "ok": 10, "7": 10, "gone": 10, "attention_pattern": 10, "detection_pattern": 10, "exclude_bo": 10, "exclude_current_token": 10, "error_measur": 10, "mul": 10, "particular": 10, "omit": 10, "comparison": 10, "exclude_bcurrent_token": 10, "wise": 10, "seq": 10, "previous_token_head": 10, "duplicate_token_head": 10, "induction_head": 10, "headnam": 10, "itself": 10, "quantifi": 10, "divid": 10, "straightforward": 10, "big": 10, "fraction": 10, "alloc": 10, "prohibit": 10, "disabl": 10, "cours": 10, "raw": 10, "interv": 10, "perfect": 10, "mismatch": 10, "precis": 10, "examin": 10, "switch": 10, "advantag": 10, "closer": 10, "fed": 10, "head_nam": 10, "ioi": 10, "spacifi": 10, "analyz": 10, "paid": 10, "plotli": 10, "express": 10, "px": 10, "def": 10, "imshow": 10, "render": 10, "xaxi": 10, "yaxi": 10, "color_continuous_midpoint": 10, "color_continuous_scal": 10, "rdbu": 10, "attention_scor": 10, "zmin": 10, "zmax": 10, "duplic": 10, "dynalist": 10, "n2zwtnoyhru1s4vnfsaq519j": 10, "2ukvedzonghl5uhugvhroxeo": 10, "_tfvup5csv5orithmqwj0gsi": 10, "0o5vohe9xezn8ertywkh7ioc": 10, "act": 10, "ident": 10, "wrap": 10, "fn": 10, "hook_nam": 10, "including_perman": 10, "arg": 10, "nice": 10, "variou": 10, "notabl": 10, "temporari": 10, "persist": 10, "fix": 10, "still": 10, "api": 10, "intent": 10, "accident": 10, "remain": 10, "goe": 10, "backward": 10, "reset_hooks_end": 10, "names_filt": 10, "callabl": 10, "incl_bwd": 10, "namesfilt": 10, "filter": 10, "lambda": 10, "fwd_hook": 10, "bwd_hook": 10, "exit": 10, "clear": 10, "whenev": 10, "reset": 10, "my_hook": 10, "hooked_loss": 10, "model_kwarg": 10, "degrad": 10, "removablehandl": 10, "dataclass": 10, "hold": 10, "perman": 10, "label_typ": 10, "suffici": 10, "automodel": 10, "autoconfig": 10, "aren": 10, "offici": 10, "pos_so_far": 10, "continu": 10, "iter": 10, "jaxtyp": 10, "new_kei": 10, "new_token": 10, "new_valu": 10, "structur": 10, "specialis": 10, "qewbv": 10, "taffccq": 10, "s_hgmqx": 10, "And": 10, "corrupted_token": 10, "clean_cach": 10, "patching_metr": 10, "patch_sett": 10, "index_axis_nam": 10, "src_po": 10, "dest_po": 10, "index_df": 10, "datafram": 10, "return_index_df": 10, "studi": 10, "counterfactu": 10, "corrupt": 10, "eiffel": 10, "tower": 10, "colosseum": 10, "come": 10, "index_to_act_nam": 10, "recov": 10, "panda": 10, "diff": 10, "corrupted_activ": 10, "chunk": 10, "fulli": 10, "fill": 10, "flatten": 10, "patched_output": 10, "patch_typ": 10, "corruptedactiv": 10, "patchedactiv": 10, "axisnam": 10, "pd": 10, "clean_activ": 10, "001": 10, "adam": 10, "50": 10, "hyperparamet": 10, "param": 10, "epoch": 10, "rate": 10, "decai": 10, "warmup": 10, "wandb_project": 10, "termin": 10, "input_slic": 10, "syntax": 10, "reduc": 10, "extra": 10, "leav": 10, "elif": 10, "1d": 10, "max_ctx": 10, "int64": 10, "select": 10, "np": 10, "valueerror": 10, "broadcast_dim": 10, "leading_dims_left": 10, "leading_dims_right": 10, "repo_nam": 10, "file_nam": 10, "subfold": 10, "home": 10, "runner": 10, "hub": 10, "force_is_torch": 10, "json": 10, "path": 10, "pth": 10, "extens": 10, "layer_typ": 10, "shorthand": 10, "hack": 10, "stuff": 10, "readabl": 10, "digit": 10, "word": 10, "k6": 10, "scale4ln1": 10, "appear": 10, "distinguish": 10, "hook_k": 10, "hook_pr": 10, "hook_emb": 10, "27": 10, "hook_norm": 10, "pre5": 10, "dataset_nam": 10, "explor": 10, "000": 10, "enorm": 10, "100gb": 10, "2tb": 10, "effort": 10, "dataload": 10, "fanci": 10, "data_dir": 10, "approx": 10, "co": 10, "divers": 10, "c4": 10, "coloss": 10, "crawl": 10, "bigger": 10, "c4_code": 10, "mix": 10, "friendli": 10, "ratio": 10, "22m": 10, "5m": 10, "20220301": 10, "en": 10, "col_nam": 10, "seq_len": 10, "altern": 10, "step_nam": 10, "final_logit": 10, "vocab_s": 10, "high": 10, "argmaxi": 10, "encourag": 10, "90": 10, "renormalis": 10, "mutual": 10, "proport": 10, "input_token": 10, "todo": 10, "edg": 10, "randn": 10, "uniqu": 10, "return_count": 10, "answer": 10, "prepend_space_to_answ": 10, "autotoken": 10, "max_length": 10, "column_nam": 10, "add_bos_token": 10, "num_proc": 10, "eo": 10, "reshap": 10, "____": 10, "drop": 10, "faster": 10, "parallelis": 10, "chop": 10, "vari": 10, "privileg": 10, "earli": 10, "cnn": 10, "swap": 10, "regardless": 10, "assist": 11, "target": 11}, "objects": {"": [[5, 0, 0, "-", "easy_transformer"], [10, 0, 0, "-", "transformer_lens"], [12, 0, 0, "-", "typing_demo"]], "transformer_lens": [[10, 0, 0, "-", "ActivationCache"], [10, 0, 0, "-", "FactoredMatrix"], [10, 0, 0, "-", "HookedEncoder"], [10, 0, 0, "-", "HookedTransformer"], [10, 0, 0, "-", "HookedTransformerConfig"], [10, 0, 0, "-", "components"], [10, 0, 0, "-", "evals"], [10, 0, 0, "-", "head_detector"], [10, 0, 0, "-", "hook_points"], [10, 0, 0, "-", "loading_from_pretrained"], [10, 0, 0, "-", "make_docs"], [10, 0, 0, "-", "past_key_value_caching"], [10, 0, 0, "-", "patching"], [10, 0, 0, "-", "train"], [11, 0, 0, "-", "utilities"], [10, 0, 0, "-", "utils"]], "transformer_lens.ActivationCache": [[10, 1, 1, "", "ActivationCache"]], "transformer_lens.ActivationCache.ActivationCache": [[10, 2, 1, "", "accumulated_resid"], [10, 2, 1, "", "apply_ln_to_stack"], [10, 2, 1, "", "apply_slice_to_batch_dim"], [10, 2, 1, "", "compute_head_results"], [10, 2, 1, "", "decompose_resid"], [10, 2, 1, "", "get_full_resid_decomposition"], [10, 2, 1, "", "get_neuron_results"], [10, 2, 1, "", "items"], [10, 2, 1, "", "keys"], [10, 2, 1, "", "logit_attrs"], [10, 2, 1, "", "remove_batch_dim"], [10, 2, 1, "", "stack_activation"], [10, 2, 1, "", "stack_head_results"], [10, 2, 1, "", "stack_neuron_results"], [10, 2, 1, "", "to"], [10, 2, 1, "", "toggle_autodiff"], [10, 2, 1, "", "values"]], "transformer_lens.FactoredMatrix": [[10, 1, 1, "", "FactoredMatrix"]], "transformer_lens.FactoredMatrix.FactoredMatrix": [[10, 3, 1, "", "AB"], [10, 3, 1, "", "BA"], [10, 3, 1, "", "S"], [10, 3, 1, "", "T"], [10, 3, 1, "", "U"], [10, 3, 1, "", "Vh"], [10, 2, 1, "", "collapse_l"], [10, 2, 1, "", "collapse_r"], [10, 3, 1, "", "eigenvalues"], [10, 2, 1, "", "get_corner"], [10, 2, 1, "", "make_even"], [10, 3, 1, "", "ndim"], [10, 2, 1, "", "norm"], [10, 3, 1, "", "pair"], [10, 2, 1, "", "svd"], [10, 2, 1, "", "unsqueeze"]], "transformer_lens.HookedEncoder": [[10, 1, 1, "", "HookedEncoder"]], "transformer_lens.HookedEncoder.HookedEncoder": [[10, 3, 1, "", "OV"], [10, 3, 1, "", "QK"], [10, 3, 1, "", "W_E"], [10, 3, 1, "", "W_E_pos"], [10, 3, 1, "", "W_K"], [10, 3, 1, "", "W_O"], [10, 3, 1, "", "W_Q"], [10, 3, 1, "", "W_U"], [10, 3, 1, "", "W_V"], [10, 3, 1, "", "W_in"], [10, 3, 1, "", "W_out"], [10, 3, 1, "", "W_pos"], [10, 2, 1, "", "all_head_labels"], [10, 3, 1, "", "b_K"], [10, 3, 1, "", "b_O"], [10, 3, 1, "", "b_Q"], [10, 3, 1, "", "b_U"], [10, 3, 1, "", "b_V"], [10, 3, 1, "", "b_in"], [10, 3, 1, "", "b_out"], [10, 2, 1, "", "cpu"], [10, 2, 1, "", "cuda"], [10, 2, 1, "", "forward"], [10, 2, 1, "", "from_pretrained"], [10, 2, 1, "", "run_with_cache"], [10, 2, 1, "", "to"], [10, 4, 1, "", "training"]], "transformer_lens.HookedTransformer": [[10, 1, 1, "", "HookedTransformer"], [10, 1, 1, "", "Output"]], "transformer_lens.HookedTransformer.HookedTransformer": [[10, 3, 1, "", "OV"], [10, 3, 1, "", "QK"], [10, 3, 1, "", "W_E"], [10, 3, 1, "", "W_E_pos"], [10, 3, 1, "", "W_K"], [10, 3, 1, "", "W_O"], [10, 3, 1, "", "W_Q"], [10, 3, 1, "", "W_U"], [10, 3, 1, "", "W_V"], [10, 3, 1, "", "W_in"], [10, 3, 1, "", "W_out"], [10, 3, 1, "", "W_pos"], [10, 2, 1, "", "accumulated_bias"], [10, 2, 1, "", "all_composition_scores"], [10, 2, 1, "", "all_head_labels"], [10, 3, 1, "", "b_K"], [10, 3, 1, "", "b_O"], [10, 3, 1, "", "b_Q"], [10, 3, 1, "", "b_U"], [10, 3, 1, "", "b_V"], [10, 3, 1, "", "b_in"], [10, 3, 1, "", "b_out"], [10, 2, 1, "", "center_unembed"], [10, 2, 1, "", "center_writing_weights"], [10, 2, 1, "", "check_hooks_to_add"], [10, 2, 1, "", "cpu"], [10, 2, 1, "", "cuda"], [10, 2, 1, "", "fold_layer_norm"], [10, 2, 1, "", "fold_value_biases"], [10, 2, 1, "", "forward"], [10, 2, 1, "", "from_pretrained"], [10, 2, 1, "", "from_pretrained_no_processing"], [10, 2, 1, "", "generate"], [10, 2, 1, "", "get_token_position"], [10, 2, 1, "", "init_weights"], [10, 2, 1, "", "load_and_process_state_dict"], [10, 2, 1, "", "load_sample_training_dataset"], [10, 2, 1, "", "loss_fn"], [10, 2, 1, "", "move_model_modules_to_device"], [10, 2, 1, "", "process_weights_"], [10, 2, 1, "", "refactor_factored_attn_matrices"], [10, 2, 1, "", "run_with_cache"], [10, 2, 1, "", "sample_datapoint"], [10, 2, 1, "", "set_tokenizer"], [10, 2, 1, "", "set_use_attn_in"], [10, 2, 1, "", "set_use_attn_result"], [10, 2, 1, "", "set_use_hook_mlp_in"], [10, 2, 1, "", "set_use_split_qkv_input"], [10, 2, 1, "", "set_use_split_qkv_normalized_input"], [10, 2, 1, "", "to"], [10, 2, 1, "", "to_single_str_token"], [10, 2, 1, "", "to_single_token"], [10, 2, 1, "", "to_str_tokens"], [10, 2, 1, "", "to_string"], [10, 2, 1, "", "to_tokens"], [10, 2, 1, "", "tokens_to_residual_directions"], [10, 4, 1, "", "training"]], "transformer_lens.HookedTransformer.Output": [[10, 4, 1, "", "logits"], [10, 4, 1, "", "loss"]], "transformer_lens.HookedTransformerConfig": [[10, 1, 1, "", "HookedTransformerConfig"]], "transformer_lens.HookedTransformerConfig.HookedTransformerConfig": [[10, 4, 1, "", "act_fn"], [10, 4, 1, "", "attention_dir"], [10, 4, 1, "", "attn_only"], [10, 4, 1, "", "attn_types"], [10, 4, 1, "", "checkpoint_index"], [10, 4, 1, "", "checkpoint_label_type"], [10, 4, 1, "", "checkpoint_value"], [10, 4, 1, "", "d_head"], [10, 4, 1, "", "d_mlp"], [10, 4, 1, "", "d_model"], [10, 4, 1, "", "d_vocab"], [10, 4, 1, "", "d_vocab_out"], [10, 4, 1, "", "device"], [10, 4, 1, "", "eps"], [10, 4, 1, "", "final_rms"], [10, 4, 1, "", "from_checkpoint"], [10, 2, 1, "", "from_dict"], [10, 4, 1, "", "gated_mlp"], [10, 4, 1, "", "init_mode"], [10, 4, 1, "", "init_weights"], [10, 4, 1, "", "initializer_range"], [10, 4, 1, "", "model_name"], [10, 4, 1, "", "n_ctx"], [10, 4, 1, "", "n_devices"], [10, 4, 1, "", "n_heads"], [10, 4, 1, "", "n_layers"], [10, 4, 1, "", "n_params"], [10, 4, 1, "", "normalization_type"], [10, 4, 1, "", "original_architecture"], [10, 4, 1, "", "parallel_attn_mlp"], [10, 4, 1, "", "positional_embedding_type"], [10, 4, 1, "", "rotary_dim"], [10, 4, 1, "", "scale_attn_by_inverse_layer_idx"], [10, 4, 1, "", "seed"], [10, 2, 1, "", "set_seed_everywhere"], [10, 2, 1, "", "to_dict"], [10, 4, 1, "", "tokenizer_name"], [10, 4, 1, "", "use_attn_in"], [10, 4, 1, "", "use_attn_result"], [10, 4, 1, "", "use_attn_scale"], [10, 4, 1, "", "use_hook_mlp_in"], [10, 4, 1, "", "use_hook_tokens"], [10, 4, 1, "", "use_local_attn"], [10, 4, 1, "", "use_split_qkv_input"], [10, 4, 1, "", "use_split_qkv_normalized_input"], [10, 4, 1, "", "window_size"]], "transformer_lens.components": [[10, 1, 1, "", "Attention"], [10, 1, 1, "", "BertBlock"], [10, 1, 1, "", "BertEmbed"], [10, 1, 1, "", "BertMLMHead"], [10, 1, 1, "", "Embed"], [10, 1, 1, "", "GatedMLP"], [10, 1, 1, "", "LayerNorm"], [10, 1, 1, "", "LayerNormPre"], [10, 1, 1, "", "MLP"], [10, 1, 1, "", "PosEmbed"], [10, 1, 1, "", "RMSNorm"], [10, 1, 1, "", "RMSNormPre"], [10, 1, 1, "", "TokenTypeEmbed"], [10, 1, 1, "", "TransformerBlock"], [10, 1, 1, "", "Unembed"]], "transformer_lens.components.Attention": [[10, 3, 1, "", "OV"], [10, 3, 1, "", "QK"], [10, 2, 1, "", "apply_causal_mask"], [10, 2, 1, "", "apply_rotary"], [10, 2, 1, "", "calculate_sin_cos_rotary"], [10, 2, 1, "", "forward"], [10, 2, 1, "", "rotary_rotate_qk"], [10, 2, 1, "", "rotate_every_two"], [10, 4, 1, "", "training"]], "transformer_lens.components.BertBlock": [[10, 2, 1, "", "forward"], [10, 4, 1, "", "training"]], "transformer_lens.components.BertEmbed": [[10, 2, 1, "", "forward"], [10, 4, 1, "", "training"]], "transformer_lens.components.BertMLMHead": [[10, 2, 1, "", "forward"], [10, 4, 1, "", "training"]], "transformer_lens.components.Embed": [[10, 2, 1, "", "forward"], [10, 4, 1, "", "training"]], "transformer_lens.components.GatedMLP": [[10, 2, 1, "", "forward"], [10, 4, 1, "", "training"]], "transformer_lens.components.LayerNorm": [[10, 2, 1, "", "forward"], [10, 4, 1, "", "training"]], "transformer_lens.components.LayerNormPre": [[10, 2, 1, "", "forward"], [10, 4, 1, "", "training"]], "transformer_lens.components.MLP": [[10, 2, 1, "", "forward"], [10, 4, 1, "", "training"]], "transformer_lens.components.PosEmbed": [[10, 2, 1, "", "forward"], [10, 4, 1, "", "training"]], "transformer_lens.components.RMSNorm": [[10, 2, 1, "", "forward"], [10, 4, 1, "", "training"]], "transformer_lens.components.RMSNormPre": [[10, 2, 1, "", "forward"], [10, 4, 1, "", "training"]], "transformer_lens.components.TokenTypeEmbed": [[10, 2, 1, "", "forward"], [10, 4, 1, "", "training"]], "transformer_lens.components.TransformerBlock": [[10, 2, 1, "", "forward"], [10, 4, 1, "", "training"]], "transformer_lens.components.Unembed": [[10, 2, 1, "", "forward"], [10, 4, 1, "", "training"]], "transformer_lens.evals": [[10, 1, 1, "", "IOIDataset"], [10, 5, 1, "", "evaluate"], [10, 5, 1, "", "evaluate_on_dataset"], [10, 5, 1, "", "induction_loss"], [10, 5, 1, "", "ioi_eval"], [10, 5, 1, "", "make_code_data_loader"], [10, 5, 1, "", "make_owt_data_loader"], [10, 5, 1, "", "make_pile_data_loader"], [10, 5, 1, "", "make_wiki_data_loader"], [10, 5, 1, "", "sanity_check"]], "transformer_lens.evals.IOIDataset": [[10, 2, 1, "", "get_default_names"], [10, 2, 1, "", "get_default_nouns"], [10, 2, 1, "", "get_default_templates"], [10, 2, 1, "", "get_sample"]], "transformer_lens.head_detector": [[10, 5, 1, "", "compute_head_attention_similarity_score"], [10, 5, 1, "", "detect_head"], [10, 5, 1, "", "get_duplicate_token_head_detection_pattern"], [10, 5, 1, "", "get_induction_head_detection_pattern"], [10, 5, 1, "", "get_previous_token_head_detection_pattern"], [10, 5, 1, "", "get_supported_heads"]], "transformer_lens.hook_points": [[10, 1, 1, "", "HookPoint"], [10, 1, 1, "", "HookedRootModule"], [10, 1, 1, "", "LensHandle"]], "transformer_lens.hook_points.HookPoint": [[10, 2, 1, "", "add_hook"], [10, 2, 1, "", "add_perma_hook"], [10, 2, 1, "", "clear_context"], [10, 2, 1, "", "forward"], [10, 2, 1, "", "layer"], [10, 2, 1, "", "remove_hooks"], [10, 4, 1, "", "training"]], "transformer_lens.hook_points.HookedRootModule": [[10, 2, 1, "", "add_caching_hooks"], [10, 2, 1, "", "add_hook"], [10, 2, 1, "", "add_perma_hook"], [10, 2, 1, "", "cache_all"], [10, 2, 1, "", "cache_some"], [10, 2, 1, "", "check_and_add_hook"], [10, 2, 1, "", "check_hooks_to_add"], [10, 2, 1, "", "clear_contexts"], [10, 2, 1, "", "get_caching_hooks"], [10, 2, 1, "", "hook_points"], [10, 2, 1, "", "hooks"], [10, 2, 1, "", "remove_all_hook_fns"], [10, 2, 1, "", "reset_hooks"], [10, 2, 1, "", "run_with_cache"], [10, 2, 1, "", "run_with_hooks"], [10, 2, 1, "", "setup"], [10, 4, 1, "", "training"]], "transformer_lens.hook_points.LensHandle": [[10, 4, 1, "id0", "context_level"], [10, 4, 1, "id7", "hook"], [10, 4, 1, "id8", "is_permanent"]], "transformer_lens.loading_from_pretrained": [[10, 1, 1, "", "Config"], [10, 5, 1, "", "get_checkpoint_labels"], [10, 5, 1, "", "get_num_params_of_pretrained"], [10, 5, 1, "", "get_pretrained_model_config"]], "transformer_lens.loading_from_pretrained.Config": [[10, 4, 1, "", "d_head"], [10, 4, 1, "", "d_mlp"], [10, 4, 1, "", "d_model"], [10, 4, 1, "", "d_vocab"], [10, 4, 1, "", "debug"], [10, 4, 1, "", "init_range"], [10, 4, 1, "", "layer_norm_eps"], [10, 4, 1, "", "n_ctx"], [10, 4, 1, "", "n_heads"], [10, 4, 1, "", "n_layers"]], "transformer_lens.past_key_value_caching": [[10, 1, 1, "", "HookedTransformerKeyValueCache"], [10, 1, 1, "", "HookedTransformerKeyValueCacheEntry"]], "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache": [[10, 4, 1, "", "entries"], [10, 2, 1, "", "init_cache"]], "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry": [[10, 2, 1, "", "append"], [10, 2, 1, "", "init_cache_entry"], [10, 4, 1, "", "past_keys"], [10, 4, 1, "", "past_values"]], "transformer_lens.patching": [[10, 5, 1, "", "generic_activation_patch"], [10, 5, 1, "", "get_act_patch_attn_head_all_pos_every"], [10, 5, 1, "", "get_act_patch_attn_head_by_pos_every"], [10, 5, 1, "", "get_act_patch_attn_head_k_all_pos"], [10, 5, 1, "", "get_act_patch_attn_head_k_by_pos"], [10, 5, 1, "", "get_act_patch_attn_head_out_all_pos"], [10, 5, 1, "", "get_act_patch_attn_head_out_by_pos"], [10, 5, 1, "", "get_act_patch_attn_head_pattern_all_pos"], [10, 5, 1, "", "get_act_patch_attn_head_pattern_by_pos"], [10, 5, 1, "", "get_act_patch_attn_head_pattern_dest_src_pos"], [10, 5, 1, "", "get_act_patch_attn_head_q_all_pos"], [10, 5, 1, "", "get_act_patch_attn_head_q_by_pos"], [10, 5, 1, "", "get_act_patch_attn_head_v_all_pos"], [10, 5, 1, "", "get_act_patch_attn_head_v_by_pos"], [10, 5, 1, "", "get_act_patch_attn_out"], [10, 5, 1, "", "get_act_patch_block_every"], [10, 5, 1, "", "get_act_patch_mlp_out"], [10, 5, 1, "", "get_act_patch_resid_mid"], [10, 5, 1, "", "get_act_patch_resid_pre"], [10, 5, 1, "", "layer_head_dest_src_pos_pattern_patch_setter"], [10, 5, 1, "", "layer_head_pattern_patch_setter"], [10, 5, 1, "", "layer_head_pos_pattern_patch_setter"], [10, 5, 1, "", "layer_head_vector_patch_setter"], [10, 5, 1, "", "layer_pos_head_vector_patch_setter"], [10, 5, 1, "", "layer_pos_patch_setter"]], "transformer_lens.train": [[10, 1, 1, "", "HookedTransformerTrainConfig"], [10, 5, 1, "", "train"]], "transformer_lens.train.HookedTransformerTrainConfig": [[10, 4, 1, "", "batch_size"], [10, 4, 1, "", "device"], [10, 4, 1, "", "lr"], [10, 4, 1, "", "max_grad_norm"], [10, 4, 1, "", "max_steps"], [10, 4, 1, "", "momentum"], [10, 4, 1, "", "num_epochs"], [10, 4, 1, "", "optimizer_name"], [10, 4, 1, "", "print_every"], [10, 4, 1, "", "save_dir"], [10, 4, 1, "", "save_every"], [10, 4, 1, "", "seed"], [10, 4, 1, "", "wandb"], [10, 4, 1, "", "wandb_project_name"], [10, 4, 1, "", "warmup_steps"], [10, 4, 1, "", "weight_decay"]], "transformer_lens.utilities": [[11, 0, 0, "-", "devices"]], "transformer_lens.utilities.devices": [[11, 5, 1, "", "get_device_for_block_index"], [11, 5, 1, "", "move_to_and_update_config"]], "transformer_lens.utils": [[10, 1, 1, "", "Slice"], [10, 6, 1, "", "SliceInput"], [10, 5, 1, "", "composition_scores"], [10, 5, 1, "", "download_file_from_hf"], [10, 5, 1, "", "gelu_fast"], [10, 5, 1, "", "gelu_new"], [10, 5, 1, "", "get_act_name"], [10, 5, 1, "", "get_corner"], [10, 5, 1, "", "get_dataset"], [10, 5, 1, "", "is_lower_triangular"], [10, 5, 1, "", "is_square"], [10, 5, 1, "", "keep_single_column"], [10, 5, 1, "", "lm_accuracy"], [10, 5, 1, "", "lm_cross_entropy_loss"], [10, 5, 1, "", "print_gpu_mem"], [10, 5, 1, "", "remove_batch_dim"], [10, 5, 1, "", "sample_logits"], [10, 5, 1, "", "solu"], [10, 5, 1, "", "test_prompt"], [10, 5, 1, "", "to_numpy"], [10, 5, 1, "", "tokenize_and_concatenate"], [10, 5, 1, "", "transpose"]], "transformer_lens.utils.Slice": [[10, 2, 1, "", "apply"], [10, 2, 1, "", "indices"]], "typing_demo": [[12, 5, 1, "", "test"], [12, 5, 1, "", "test2"], [12, 5, 1, "", "test3"], [12, 5, 1, "", "test4"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:property", "4": "py:attribute", "5": "py:function", "6": "py:data"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "property", "Python property"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "function", "Python function"], "6": ["py", "data", "Python data"]}, "titleterms": {"citat": 0, "local": 1, "develop": 1, "devcontain": 1, "manual": 1, "setup": [1, 9], "test": 1, "galleri": 2, "get": 3, "start": [3, 4], "advic": 3, "read": 3, "code": 3, "instal": 3, "tutori": 4, "where": 4, "To": 4, "demo": 4, "easy_transform": 5, "packag": [5, 10, 11], "modul": [5, 9, 10, 11, 12], "content": [5, 10, 11], "transformerlen": [6, 8], "A": 6, "librari": 6, "mechanist": 6, "interpret": 6, "gener": 6, "languag": 6, "model": [6, 7], "properti": 7, "tabl": 7, "transformer_len": [10, 11], "subpackag": 10, "submodul": [10, 11], "activationcach": 10, "factoredmatrix": 10, "hookedencod": 10, "hookedtransform": 10, "hookedtransformerconfig": 10, "compon": 10, "eval": 10, "head_detector": 10, "hook_point": 10, "loading_from_pretrain": 10, "make_doc": 10, "past_key_value_cach": 10, "patch": 10, "train": 10, "util": [10, 11], "devic": 11, "typing_demo": 12}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 57}, "alltitles": {"Citation": [[0, "citation"]], "Local Development": [[1, "local-development"]], "DevContainer": [[1, "devcontainer"]], "Manual Setup": [[1, "manual-setup"]], "Testing": [[1, "testing"]], "Gallery": [[2, "gallery"]], "Getting Started": [[3, "getting-started"]], "Advice for Reading the Code": [[3, "advice-for-reading-the-code"]], "Installation": [[3, "installation"]], "Tutorials": [[4, "tutorials"]], "Where To Start": [[4, "where-to-start"]], "Demos": [[4, "demos"]], "easy_transformer package": [[5, "easy-transformer-package"]], "Module contents": [[5, "module-easy_transformer"], [10, "module-transformer_lens"], [11, "module-transformer_lens.utilities"]], "TransformerLens": [[6, "transformerlens"], [8, "transformerlens"]], "A Library for Mechanistic Interpretability of Generative Language Models": [[6, "a-library-for-mechanistic-interpretability-of-generative-language-models"]], "Model Properties Table": [[7, "model-properties-table"]], "setup module": [[9, "setup-module"]], "transformer_lens package": [[10, "transformer-lens-package"]], "Subpackages": [[10, "subpackages"]], "Submodules": [[10, "submodules"], [11, "submodules"]], "transformer_lens.ActivationCache module": [[10, "module-transformer_lens.ActivationCache"]], "transformer_lens.FactoredMatrix module": [[10, "module-transformer_lens.FactoredMatrix"]], "transformer_lens.HookedEncoder module": [[10, "module-transformer_lens.HookedEncoder"]], "transformer_lens.HookedTransformer module": [[10, "module-transformer_lens.HookedTransformer"]], "transformer_lens.HookedTransformerConfig module": [[10, "module-transformer_lens.HookedTransformerConfig"]], "transformer_lens.components module": [[10, "module-transformer_lens.components"]], "transformer_lens.evals module": [[10, "module-transformer_lens.evals"]], "transformer_lens.head_detector module": [[10, "module-transformer_lens.head_detector"]], "transformer_lens.hook_points module": [[10, "module-transformer_lens.hook_points"]], "transformer_lens.loading_from_pretrained module": [[10, "module-transformer_lens.loading_from_pretrained"]], "transformer_lens.make_docs module": [[10, "module-transformer_lens.make_docs"]], "transformer_lens.past_key_value_caching module": [[10, "module-transformer_lens.past_key_value_caching"]], "transformer_lens.patching module": [[10, "module-transformer_lens.patching"]], "transformer_lens.train module": [[10, "module-transformer_lens.train"]], "transformer_lens.utils module": [[10, "module-transformer_lens.utils"]], "transformer_lens.utilities package": [[11, "transformer-lens-utilities-package"]], "transformer_lens.utilities.devices module": [[11, "module-transformer_lens.utilities.devices"]], "typing_demo module": [[12, "module-typing_demo"]]}, "indexentries": {"easy_transformer": [[5, "module-easy_transformer"]], "module": [[5, "module-easy_transformer"], [10, "module-transformer_lens"], [10, "module-transformer_lens.ActivationCache"], [10, "module-transformer_lens.FactoredMatrix"], [10, "module-transformer_lens.HookedEncoder"], [10, "module-transformer_lens.HookedTransformer"], [10, "module-transformer_lens.HookedTransformerConfig"], [10, "module-transformer_lens.components"], [10, "module-transformer_lens.evals"], [10, "module-transformer_lens.head_detector"], [10, "module-transformer_lens.hook_points"], [10, "module-transformer_lens.loading_from_pretrained"], [10, "module-transformer_lens.make_docs"], [10, "module-transformer_lens.past_key_value_caching"], [10, "module-transformer_lens.patching"], [10, "module-transformer_lens.train"], [10, "module-transformer_lens.utils"], [11, "module-transformer_lens.utilities"], [11, "module-transformer_lens.utilities.devices"], [12, "module-typing_demo"]], "ab (transformer_lens.factoredmatrix.factoredmatrix property)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.AB"]], "activationcache (class in transformer_lens.activationcache)": [[10, "transformer_lens.ActivationCache.ActivationCache"]], "attention (class in transformer_lens.components)": [[10, "transformer_lens.components.Attention"]], "ba (transformer_lens.factoredmatrix.factoredmatrix property)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.BA"]], "bertblock (class in transformer_lens.components)": [[10, "transformer_lens.components.BertBlock"]], "bertembed (class in transformer_lens.components)": [[10, "transformer_lens.components.BertEmbed"]], "bertmlmhead (class in transformer_lens.components)": [[10, "transformer_lens.components.BertMLMHead"]], "config (class in transformer_lens.loading_from_pretrained)": [[10, "transformer_lens.loading_from_pretrained.Config"]], "embed (class in transformer_lens.components)": [[10, "transformer_lens.components.Embed"]], "factoredmatrix (class in transformer_lens.factoredmatrix)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix"]], "gatedmlp (class in transformer_lens.components)": [[10, "transformer_lens.components.GatedMLP"]], "hookpoint (class in transformer_lens.hook_points)": [[10, "transformer_lens.hook_points.HookPoint"]], "hookedencoder (class in transformer_lens.hookedencoder)": [[10, "transformer_lens.HookedEncoder.HookedEncoder"]], "hookedrootmodule (class in transformer_lens.hook_points)": [[10, "transformer_lens.hook_points.HookedRootModule"]], "hookedtransformer (class in transformer_lens.hookedtransformer)": [[10, "transformer_lens.HookedTransformer.HookedTransformer"]], "hookedtransformerconfig (class in transformer_lens.hookedtransformerconfig)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig"]], "hookedtransformerkeyvaluecache (class in transformer_lens.past_key_value_caching)": [[10, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache"]], "hookedtransformerkeyvaluecacheentry (class in transformer_lens.past_key_value_caching)": [[10, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry"]], "hookedtransformertrainconfig (class in transformer_lens.train)": [[10, "transformer_lens.train.HookedTransformerTrainConfig"]], "ioidataset (class in transformer_lens.evals)": [[10, "transformer_lens.evals.IOIDataset"]], "layernorm (class in transformer_lens.components)": [[10, "transformer_lens.components.LayerNorm"]], "layernormpre (class in transformer_lens.components)": [[10, "transformer_lens.components.LayerNormPre"]], "lenshandle (class in transformer_lens.hook_points)": [[10, "transformer_lens.hook_points.LensHandle"]], "mlp (class in transformer_lens.components)": [[10, "transformer_lens.components.MLP"]], "ov (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.OV"]], "ov (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.OV"]], "ov (transformer_lens.components.attention property)": [[10, "transformer_lens.components.Attention.OV"]], "output (class in transformer_lens.hookedtransformer)": [[10, "transformer_lens.HookedTransformer.Output"]], "posembed (class in transformer_lens.components)": [[10, "transformer_lens.components.PosEmbed"]], "qk (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.QK"]], "qk (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.QK"]], "qk (transformer_lens.components.attention property)": [[10, "transformer_lens.components.Attention.QK"]], "rmsnorm (class in transformer_lens.components)": [[10, "transformer_lens.components.RMSNorm"]], "rmsnormpre (class in transformer_lens.components)": [[10, "transformer_lens.components.RMSNormPre"]], "s (transformer_lens.factoredmatrix.factoredmatrix property)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.S"]], "slice (class in transformer_lens.utils)": [[10, "transformer_lens.utils.Slice"]], "sliceinput (in module transformer_lens.utils)": [[10, "transformer_lens.utils.SliceInput"]], "t (transformer_lens.factoredmatrix.factoredmatrix property)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.T"]], "tokentypeembed (class in transformer_lens.components)": [[10, "transformer_lens.components.TokenTypeEmbed"]], "transformerblock (class in transformer_lens.components)": [[10, "transformer_lens.components.TransformerBlock"]], "u (transformer_lens.factoredmatrix.factoredmatrix property)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.U"]], "unembed (class in transformer_lens.components)": [[10, "transformer_lens.components.Unembed"]], "vh (transformer_lens.factoredmatrix.factoredmatrix property)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.Vh"]], "w_e (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.W_E"]], "w_e (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.W_E"]], "w_e_pos (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.W_E_pos"]], "w_e_pos (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.W_E_pos"]], "w_k (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.W_K"]], "w_k (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.W_K"]], "w_o (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.W_O"]], "w_o (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.W_O"]], "w_q (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.W_Q"]], "w_q (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.W_Q"]], "w_u (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.W_U"]], "w_u (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.W_U"]], "w_v (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.W_V"]], "w_v (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.W_V"]], "w_in (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.W_in"]], "w_in (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.W_in"]], "w_out (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.W_out"]], "w_out (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.W_out"]], "w_pos (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.W_pos"]], "w_pos (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.W_pos"]], "accumulated_bias() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.accumulated_bias"]], "accumulated_resid() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.accumulated_resid"]], "act_fn (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.act_fn"]], "add_caching_hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[10, "transformer_lens.hook_points.HookedRootModule.add_caching_hooks"]], "add_hook() (transformer_lens.hook_points.hookpoint method)": [[10, "transformer_lens.hook_points.HookPoint.add_hook"]], "add_hook() (transformer_lens.hook_points.hookedrootmodule method)": [[10, "transformer_lens.hook_points.HookedRootModule.add_hook"]], "add_perma_hook() (transformer_lens.hook_points.hookpoint method)": [[10, "transformer_lens.hook_points.HookPoint.add_perma_hook"]], "add_perma_hook() (transformer_lens.hook_points.hookedrootmodule method)": [[10, "transformer_lens.hook_points.HookedRootModule.add_perma_hook"]], "all_composition_scores() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.all_composition_scores"]], "all_head_labels() (transformer_lens.hookedencoder.hookedencoder method)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.all_head_labels"]], "all_head_labels() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.all_head_labels"]], "append() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry method)": [[10, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.append"]], "apply() (transformer_lens.utils.slice method)": [[10, "transformer_lens.utils.Slice.apply"]], "apply_causal_mask() (transformer_lens.components.attention method)": [[10, "transformer_lens.components.Attention.apply_causal_mask"]], "apply_ln_to_stack() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.apply_ln_to_stack"]], "apply_rotary() (transformer_lens.components.attention method)": [[10, "transformer_lens.components.Attention.apply_rotary"]], "apply_slice_to_batch_dim() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.apply_slice_to_batch_dim"]], "attention_dir (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.attention_dir"]], "attn_only (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.attn_only"]], "attn_types (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.attn_types"]], "b_k (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.b_K"]], "b_k (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.b_K"]], "b_o (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.b_O"]], "b_o (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.b_O"]], "b_q (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.b_Q"]], "b_q (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.b_Q"]], "b_u (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.b_U"]], "b_u (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.b_U"]], "b_v (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.b_V"]], "b_v (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.b_V"]], "b_in (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.b_in"]], "b_in (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.b_in"]], "b_out (transformer_lens.hookedencoder.hookedencoder property)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.b_out"]], "b_out (transformer_lens.hookedtransformer.hookedtransformer property)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.b_out"]], "batch_size (transformer_lens.train.hookedtransformertrainconfig attribute)": [[10, "transformer_lens.train.HookedTransformerTrainConfig.batch_size"]], "cache_all() (transformer_lens.hook_points.hookedrootmodule method)": [[10, "transformer_lens.hook_points.HookedRootModule.cache_all"]], "cache_some() (transformer_lens.hook_points.hookedrootmodule method)": [[10, "transformer_lens.hook_points.HookedRootModule.cache_some"]], "calculate_sin_cos_rotary() (transformer_lens.components.attention method)": [[10, "transformer_lens.components.Attention.calculate_sin_cos_rotary"]], "center_unembed() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.center_unembed"]], "center_writing_weights() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.center_writing_weights"]], "check_and_add_hook() (transformer_lens.hook_points.hookedrootmodule method)": [[10, "transformer_lens.hook_points.HookedRootModule.check_and_add_hook"]], "check_hooks_to_add() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.check_hooks_to_add"]], "check_hooks_to_add() (transformer_lens.hook_points.hookedrootmodule method)": [[10, "transformer_lens.hook_points.HookedRootModule.check_hooks_to_add"]], "checkpoint_index (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.checkpoint_index"]], "checkpoint_label_type (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.checkpoint_label_type"]], "checkpoint_value (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.checkpoint_value"]], "clear_context() (transformer_lens.hook_points.hookpoint method)": [[10, "transformer_lens.hook_points.HookPoint.clear_context"]], "clear_contexts() (transformer_lens.hook_points.hookedrootmodule method)": [[10, "transformer_lens.hook_points.HookedRootModule.clear_contexts"]], "collapse_l() (transformer_lens.factoredmatrix.factoredmatrix method)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.collapse_l"]], "collapse_r() (transformer_lens.factoredmatrix.factoredmatrix method)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.collapse_r"]], "composition_scores() (in module transformer_lens.utils)": [[10, "transformer_lens.utils.composition_scores"]], "compute_head_attention_similarity_score() (in module transformer_lens.head_detector)": [[10, "transformer_lens.head_detector.compute_head_attention_similarity_score"]], "compute_head_results() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.compute_head_results"]], "context_level (transformer_lens.hook_points.lenshandle attribute)": [[10, "id0"], [10, "transformer_lens.hook_points.LensHandle.context_level"]], "cpu() (transformer_lens.hookedencoder.hookedencoder method)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.cpu"]], "cpu() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.cpu"]], "cuda() (transformer_lens.hookedencoder.hookedencoder method)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.cuda"]], "cuda() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.cuda"]], "d_head (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_head"]], "d_head (transformer_lens.loading_from_pretrained.config attribute)": [[10, "transformer_lens.loading_from_pretrained.Config.d_head"]], "d_mlp (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_mlp"]], "d_mlp (transformer_lens.loading_from_pretrained.config attribute)": [[10, "transformer_lens.loading_from_pretrained.Config.d_mlp"]], "d_model (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_model"]], "d_model (transformer_lens.loading_from_pretrained.config attribute)": [[10, "transformer_lens.loading_from_pretrained.Config.d_model"]], "d_vocab (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_vocab"]], "d_vocab (transformer_lens.loading_from_pretrained.config attribute)": [[10, "transformer_lens.loading_from_pretrained.Config.d_vocab"]], "d_vocab_out (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.d_vocab_out"]], "debug (transformer_lens.loading_from_pretrained.config attribute)": [[10, "transformer_lens.loading_from_pretrained.Config.debug"]], "decompose_resid() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.decompose_resid"]], "detect_head() (in module transformer_lens.head_detector)": [[10, "transformer_lens.head_detector.detect_head"]], "device (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.device"]], "device (transformer_lens.train.hookedtransformertrainconfig attribute)": [[10, "transformer_lens.train.HookedTransformerTrainConfig.device"]], "download_file_from_hf() (in module transformer_lens.utils)": [[10, "transformer_lens.utils.download_file_from_hf"]], "eigenvalues (transformer_lens.factoredmatrix.factoredmatrix property)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.eigenvalues"]], "entries (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache attribute)": [[10, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.entries"]], "eps (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.eps"]], "evaluate() (in module transformer_lens.evals)": [[10, "transformer_lens.evals.evaluate"]], "evaluate_on_dataset() (in module transformer_lens.evals)": [[10, "transformer_lens.evals.evaluate_on_dataset"]], "final_rms (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.final_rms"]], "fold_layer_norm() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.fold_layer_norm"]], "fold_value_biases() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.fold_value_biases"]], "forward() (transformer_lens.hookedencoder.hookedencoder method)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.forward"]], "forward() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.forward"]], "forward() (transformer_lens.components.attention method)": [[10, "transformer_lens.components.Attention.forward"]], "forward() (transformer_lens.components.bertblock method)": [[10, "transformer_lens.components.BertBlock.forward"]], "forward() (transformer_lens.components.bertembed method)": [[10, "transformer_lens.components.BertEmbed.forward"]], "forward() (transformer_lens.components.bertmlmhead method)": [[10, "transformer_lens.components.BertMLMHead.forward"]], "forward() (transformer_lens.components.embed method)": [[10, "transformer_lens.components.Embed.forward"]], "forward() (transformer_lens.components.gatedmlp method)": [[10, "transformer_lens.components.GatedMLP.forward"]], "forward() (transformer_lens.components.layernorm method)": [[10, "transformer_lens.components.LayerNorm.forward"]], "forward() (transformer_lens.components.layernormpre method)": [[10, "transformer_lens.components.LayerNormPre.forward"]], "forward() (transformer_lens.components.mlp method)": [[10, "transformer_lens.components.MLP.forward"]], "forward() (transformer_lens.components.posembed method)": [[10, "transformer_lens.components.PosEmbed.forward"]], "forward() (transformer_lens.components.rmsnorm method)": [[10, "transformer_lens.components.RMSNorm.forward"]], "forward() (transformer_lens.components.rmsnormpre method)": [[10, "transformer_lens.components.RMSNormPre.forward"]], "forward() (transformer_lens.components.tokentypeembed method)": [[10, "transformer_lens.components.TokenTypeEmbed.forward"]], "forward() (transformer_lens.components.transformerblock method)": [[10, "transformer_lens.components.TransformerBlock.forward"]], "forward() (transformer_lens.components.unembed method)": [[10, "transformer_lens.components.Unembed.forward"]], "forward() (transformer_lens.hook_points.hookpoint method)": [[10, "transformer_lens.hook_points.HookPoint.forward"]], "from_checkpoint (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.from_checkpoint"]], "from_dict() (transformer_lens.hookedtransformerconfig.hookedtransformerconfig class method)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.from_dict"]], "from_pretrained() (transformer_lens.hookedencoder.hookedencoder class method)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.from_pretrained"]], "from_pretrained() (transformer_lens.hookedtransformer.hookedtransformer class method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.from_pretrained"]], "from_pretrained_no_processing() (transformer_lens.hookedtransformer.hookedtransformer class method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.from_pretrained_no_processing"]], "gated_mlp (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.gated_mlp"]], "gelu_fast() (in module transformer_lens.utils)": [[10, "transformer_lens.utils.gelu_fast"]], "gelu_new() (in module transformer_lens.utils)": [[10, "transformer_lens.utils.gelu_new"]], "generate() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.generate"]], "generic_activation_patch() (in module transformer_lens.patching)": [[10, "transformer_lens.patching.generic_activation_patch"]], "get_act_name() (in module transformer_lens.utils)": [[10, "transformer_lens.utils.get_act_name"]], "get_act_patch_attn_head_all_pos_every() (in module transformer_lens.patching)": [[10, "transformer_lens.patching.get_act_patch_attn_head_all_pos_every"]], "get_act_patch_attn_head_by_pos_every() (in module transformer_lens.patching)": [[10, "transformer_lens.patching.get_act_patch_attn_head_by_pos_every"]], "get_act_patch_attn_head_k_all_pos() (in module transformer_lens.patching)": [[10, "transformer_lens.patching.get_act_patch_attn_head_k_all_pos"]], "get_act_patch_attn_head_k_by_pos() (in module transformer_lens.patching)": [[10, "transformer_lens.patching.get_act_patch_attn_head_k_by_pos"]], "get_act_patch_attn_head_out_all_pos() (in module transformer_lens.patching)": [[10, "transformer_lens.patching.get_act_patch_attn_head_out_all_pos"]], "get_act_patch_attn_head_out_by_pos() (in module transformer_lens.patching)": [[10, "transformer_lens.patching.get_act_patch_attn_head_out_by_pos"]], "get_act_patch_attn_head_pattern_all_pos() (in module transformer_lens.patching)": [[10, "transformer_lens.patching.get_act_patch_attn_head_pattern_all_pos"]], "get_act_patch_attn_head_pattern_by_pos() (in module transformer_lens.patching)": [[10, "transformer_lens.patching.get_act_patch_attn_head_pattern_by_pos"]], "get_act_patch_attn_head_pattern_dest_src_pos() (in module transformer_lens.patching)": [[10, "transformer_lens.patching.get_act_patch_attn_head_pattern_dest_src_pos"]], "get_act_patch_attn_head_q_all_pos() (in module transformer_lens.patching)": [[10, "transformer_lens.patching.get_act_patch_attn_head_q_all_pos"]], "get_act_patch_attn_head_q_by_pos() (in module transformer_lens.patching)": [[10, "transformer_lens.patching.get_act_patch_attn_head_q_by_pos"]], "get_act_patch_attn_head_v_all_pos() (in module transformer_lens.patching)": [[10, "transformer_lens.patching.get_act_patch_attn_head_v_all_pos"]], "get_act_patch_attn_head_v_by_pos() (in module transformer_lens.patching)": [[10, "transformer_lens.patching.get_act_patch_attn_head_v_by_pos"]], "get_act_patch_attn_out() (in module transformer_lens.patching)": [[10, "transformer_lens.patching.get_act_patch_attn_out"]], "get_act_patch_block_every() (in module transformer_lens.patching)": [[10, "transformer_lens.patching.get_act_patch_block_every"]], "get_act_patch_mlp_out() (in module transformer_lens.patching)": [[10, "transformer_lens.patching.get_act_patch_mlp_out"]], "get_act_patch_resid_mid() (in module transformer_lens.patching)": [[10, "transformer_lens.patching.get_act_patch_resid_mid"]], "get_act_patch_resid_pre() (in module transformer_lens.patching)": [[10, "transformer_lens.patching.get_act_patch_resid_pre"]], "get_caching_hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[10, "transformer_lens.hook_points.HookedRootModule.get_caching_hooks"]], "get_checkpoint_labels() (in module transformer_lens.loading_from_pretrained)": [[10, "transformer_lens.loading_from_pretrained.get_checkpoint_labels"]], "get_corner() (in module transformer_lens.utils)": [[10, "transformer_lens.utils.get_corner"]], "get_corner() (transformer_lens.factoredmatrix.factoredmatrix method)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.get_corner"]], "get_dataset() (in module transformer_lens.utils)": [[10, "transformer_lens.utils.get_dataset"]], "get_default_names() (transformer_lens.evals.ioidataset static method)": [[10, "transformer_lens.evals.IOIDataset.get_default_names"]], "get_default_nouns() (transformer_lens.evals.ioidataset static method)": [[10, "transformer_lens.evals.IOIDataset.get_default_nouns"]], "get_default_templates() (transformer_lens.evals.ioidataset static method)": [[10, "transformer_lens.evals.IOIDataset.get_default_templates"]], "get_duplicate_token_head_detection_pattern() (in module transformer_lens.head_detector)": [[10, "transformer_lens.head_detector.get_duplicate_token_head_detection_pattern"]], "get_full_resid_decomposition() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.get_full_resid_decomposition"]], "get_induction_head_detection_pattern() (in module transformer_lens.head_detector)": [[10, "transformer_lens.head_detector.get_induction_head_detection_pattern"]], "get_neuron_results() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.get_neuron_results"]], "get_num_params_of_pretrained() (in module transformer_lens.loading_from_pretrained)": [[10, "transformer_lens.loading_from_pretrained.get_num_params_of_pretrained"]], "get_pretrained_model_config() (in module transformer_lens.loading_from_pretrained)": [[10, "transformer_lens.loading_from_pretrained.get_pretrained_model_config"]], "get_previous_token_head_detection_pattern() (in module transformer_lens.head_detector)": [[10, "transformer_lens.head_detector.get_previous_token_head_detection_pattern"]], "get_sample() (transformer_lens.evals.ioidataset method)": [[10, "transformer_lens.evals.IOIDataset.get_sample"]], "get_supported_heads() (in module transformer_lens.head_detector)": [[10, "transformer_lens.head_detector.get_supported_heads"]], "get_token_position() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.get_token_position"]], "hook (transformer_lens.hook_points.lenshandle attribute)": [[10, "id7"], [10, "transformer_lens.hook_points.LensHandle.hook"]], "hook_points() (transformer_lens.hook_points.hookedrootmodule method)": [[10, "transformer_lens.hook_points.HookedRootModule.hook_points"]], "hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[10, "transformer_lens.hook_points.HookedRootModule.hooks"]], "indices() (transformer_lens.utils.slice method)": [[10, "transformer_lens.utils.Slice.indices"]], "induction_loss() (in module transformer_lens.evals)": [[10, "transformer_lens.evals.induction_loss"]], "init_cache() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecache class method)": [[10, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCache.init_cache"]], "init_cache_entry() (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry class method)": [[10, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.init_cache_entry"]], "init_mode (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.init_mode"]], "init_range (transformer_lens.loading_from_pretrained.config attribute)": [[10, "transformer_lens.loading_from_pretrained.Config.init_range"]], "init_weights (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.init_weights"]], "init_weights() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.init_weights"]], "initializer_range (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.initializer_range"]], "ioi_eval() (in module transformer_lens.evals)": [[10, "transformer_lens.evals.ioi_eval"]], "is_lower_triangular() (in module transformer_lens.utils)": [[10, "transformer_lens.utils.is_lower_triangular"]], "is_permanent (transformer_lens.hook_points.lenshandle attribute)": [[10, "id8"], [10, "transformer_lens.hook_points.LensHandle.is_permanent"]], "is_square() (in module transformer_lens.utils)": [[10, "transformer_lens.utils.is_square"]], "items() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.items"]], "keep_single_column() (in module transformer_lens.utils)": [[10, "transformer_lens.utils.keep_single_column"]], "keys() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.keys"]], "layer() (transformer_lens.hook_points.hookpoint method)": [[10, "transformer_lens.hook_points.HookPoint.layer"]], "layer_head_dest_src_pos_pattern_patch_setter() (in module transformer_lens.patching)": [[10, "transformer_lens.patching.layer_head_dest_src_pos_pattern_patch_setter"]], "layer_head_pattern_patch_setter() (in module transformer_lens.patching)": [[10, "transformer_lens.patching.layer_head_pattern_patch_setter"]], "layer_head_pos_pattern_patch_setter() (in module transformer_lens.patching)": [[10, "transformer_lens.patching.layer_head_pos_pattern_patch_setter"]], "layer_head_vector_patch_setter() (in module transformer_lens.patching)": [[10, "transformer_lens.patching.layer_head_vector_patch_setter"]], "layer_norm_eps (transformer_lens.loading_from_pretrained.config attribute)": [[10, "transformer_lens.loading_from_pretrained.Config.layer_norm_eps"]], "layer_pos_head_vector_patch_setter() (in module transformer_lens.patching)": [[10, "transformer_lens.patching.layer_pos_head_vector_patch_setter"]], "layer_pos_patch_setter() (in module transformer_lens.patching)": [[10, "transformer_lens.patching.layer_pos_patch_setter"]], "lm_accuracy() (in module transformer_lens.utils)": [[10, "transformer_lens.utils.lm_accuracy"]], "lm_cross_entropy_loss() (in module transformer_lens.utils)": [[10, "transformer_lens.utils.lm_cross_entropy_loss"]], "load_and_process_state_dict() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.load_and_process_state_dict"]], "load_sample_training_dataset() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.load_sample_training_dataset"]], "logit_attrs() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.logit_attrs"]], "logits (transformer_lens.hookedtransformer.output attribute)": [[10, "transformer_lens.HookedTransformer.Output.logits"]], "loss (transformer_lens.hookedtransformer.output attribute)": [[10, "transformer_lens.HookedTransformer.Output.loss"]], "loss_fn() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.loss_fn"]], "lr (transformer_lens.train.hookedtransformertrainconfig attribute)": [[10, "transformer_lens.train.HookedTransformerTrainConfig.lr"]], "make_code_data_loader() (in module transformer_lens.evals)": [[10, "transformer_lens.evals.make_code_data_loader"]], "make_even() (transformer_lens.factoredmatrix.factoredmatrix method)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.make_even"]], "make_owt_data_loader() (in module transformer_lens.evals)": [[10, "transformer_lens.evals.make_owt_data_loader"]], "make_pile_data_loader() (in module transformer_lens.evals)": [[10, "transformer_lens.evals.make_pile_data_loader"]], "make_wiki_data_loader() (in module transformer_lens.evals)": [[10, "transformer_lens.evals.make_wiki_data_loader"]], "max_grad_norm (transformer_lens.train.hookedtransformertrainconfig attribute)": [[10, "transformer_lens.train.HookedTransformerTrainConfig.max_grad_norm"]], "max_steps (transformer_lens.train.hookedtransformertrainconfig attribute)": [[10, "transformer_lens.train.HookedTransformerTrainConfig.max_steps"]], "model_name (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.model_name"]], "momentum (transformer_lens.train.hookedtransformertrainconfig attribute)": [[10, "transformer_lens.train.HookedTransformerTrainConfig.momentum"]], "move_model_modules_to_device() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.move_model_modules_to_device"]], "n_ctx (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_ctx"]], "n_ctx (transformer_lens.loading_from_pretrained.config attribute)": [[10, "transformer_lens.loading_from_pretrained.Config.n_ctx"]], "n_devices (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_devices"]], "n_heads (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_heads"]], "n_heads (transformer_lens.loading_from_pretrained.config attribute)": [[10, "transformer_lens.loading_from_pretrained.Config.n_heads"]], "n_layers (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_layers"]], "n_layers (transformer_lens.loading_from_pretrained.config attribute)": [[10, "transformer_lens.loading_from_pretrained.Config.n_layers"]], "n_params (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.n_params"]], "ndim (transformer_lens.factoredmatrix.factoredmatrix property)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.ndim"]], "norm() (transformer_lens.factoredmatrix.factoredmatrix method)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.norm"]], "normalization_type (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.normalization_type"]], "num_epochs (transformer_lens.train.hookedtransformertrainconfig attribute)": [[10, "transformer_lens.train.HookedTransformerTrainConfig.num_epochs"]], "optimizer_name (transformer_lens.train.hookedtransformertrainconfig attribute)": [[10, "transformer_lens.train.HookedTransformerTrainConfig.optimizer_name"]], "original_architecture (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.original_architecture"]], "pair (transformer_lens.factoredmatrix.factoredmatrix property)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.pair"]], "parallel_attn_mlp (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.parallel_attn_mlp"]], "past_keys (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry attribute)": [[10, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.past_keys"]], "past_values (transformer_lens.past_key_value_caching.hookedtransformerkeyvaluecacheentry attribute)": [[10, "transformer_lens.past_key_value_caching.HookedTransformerKeyValueCacheEntry.past_values"]], "positional_embedding_type (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.positional_embedding_type"]], "print_every (transformer_lens.train.hookedtransformertrainconfig attribute)": [[10, "transformer_lens.train.HookedTransformerTrainConfig.print_every"]], "print_gpu_mem() (in module transformer_lens.utils)": [[10, "transformer_lens.utils.print_gpu_mem"]], "process_weights_() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.process_weights_"]], "refactor_factored_attn_matrices() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.refactor_factored_attn_matrices"]], "remove_all_hook_fns() (transformer_lens.hook_points.hookedrootmodule method)": [[10, "transformer_lens.hook_points.HookedRootModule.remove_all_hook_fns"]], "remove_batch_dim() (in module transformer_lens.utils)": [[10, "transformer_lens.utils.remove_batch_dim"]], "remove_batch_dim() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.remove_batch_dim"]], "remove_hooks() (transformer_lens.hook_points.hookpoint method)": [[10, "transformer_lens.hook_points.HookPoint.remove_hooks"]], "reset_hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[10, "transformer_lens.hook_points.HookedRootModule.reset_hooks"]], "rotary_dim (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.rotary_dim"]], "rotary_rotate_qk() (transformer_lens.components.attention method)": [[10, "transformer_lens.components.Attention.rotary_rotate_qk"]], "rotate_every_two() (transformer_lens.components.attention method)": [[10, "transformer_lens.components.Attention.rotate_every_two"]], "run_with_cache() (transformer_lens.hookedencoder.hookedencoder method)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.run_with_cache"]], "run_with_cache() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.run_with_cache"]], "run_with_cache() (transformer_lens.hook_points.hookedrootmodule method)": [[10, "transformer_lens.hook_points.HookedRootModule.run_with_cache"]], "run_with_hooks() (transformer_lens.hook_points.hookedrootmodule method)": [[10, "transformer_lens.hook_points.HookedRootModule.run_with_hooks"]], "sample_datapoint() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.sample_datapoint"]], "sample_logits() (in module transformer_lens.utils)": [[10, "transformer_lens.utils.sample_logits"]], "sanity_check() (in module transformer_lens.evals)": [[10, "transformer_lens.evals.sanity_check"]], "save_dir (transformer_lens.train.hookedtransformertrainconfig attribute)": [[10, "transformer_lens.train.HookedTransformerTrainConfig.save_dir"]], "save_every (transformer_lens.train.hookedtransformertrainconfig attribute)": [[10, "transformer_lens.train.HookedTransformerTrainConfig.save_every"]], "scale_attn_by_inverse_layer_idx (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.scale_attn_by_inverse_layer_idx"]], "seed (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.seed"]], "seed (transformer_lens.train.hookedtransformertrainconfig attribute)": [[10, "transformer_lens.train.HookedTransformerTrainConfig.seed"]], "set_seed_everywhere() (transformer_lens.hookedtransformerconfig.hookedtransformerconfig method)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.set_seed_everywhere"]], "set_tokenizer() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.set_tokenizer"]], "set_use_attn_in() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.set_use_attn_in"]], "set_use_attn_result() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.set_use_attn_result"]], "set_use_hook_mlp_in() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.set_use_hook_mlp_in"]], "set_use_split_qkv_input() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.set_use_split_qkv_input"]], "set_use_split_qkv_normalized_input() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.set_use_split_qkv_normalized_input"]], "setup() (transformer_lens.hook_points.hookedrootmodule method)": [[10, "transformer_lens.hook_points.HookedRootModule.setup"]], "solu() (in module transformer_lens.utils)": [[10, "transformer_lens.utils.solu"]], "stack_activation() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.stack_activation"]], "stack_head_results() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.stack_head_results"]], "stack_neuron_results() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.stack_neuron_results"]], "svd() (transformer_lens.factoredmatrix.factoredmatrix method)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.svd"]], "test_prompt() (in module transformer_lens.utils)": [[10, "transformer_lens.utils.test_prompt"]], "to() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.to"]], "to() (transformer_lens.hookedencoder.hookedencoder method)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.to"]], "to() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.to"]], "to_dict() (transformer_lens.hookedtransformerconfig.hookedtransformerconfig method)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.to_dict"]], "to_numpy() (in module transformer_lens.utils)": [[10, "transformer_lens.utils.to_numpy"]], "to_single_str_token() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.to_single_str_token"]], "to_single_token() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.to_single_token"]], "to_str_tokens() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.to_str_tokens"]], "to_string() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.to_string"]], "to_tokens() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.to_tokens"]], "toggle_autodiff() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.toggle_autodiff"]], "tokenize_and_concatenate() (in module transformer_lens.utils)": [[10, "transformer_lens.utils.tokenize_and_concatenate"]], "tokenizer_name (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.tokenizer_name"]], "tokens_to_residual_directions() (transformer_lens.hookedtransformer.hookedtransformer method)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.tokens_to_residual_directions"]], "train() (in module transformer_lens.train)": [[10, "transformer_lens.train.train"]], "training (transformer_lens.hookedencoder.hookedencoder attribute)": [[10, "transformer_lens.HookedEncoder.HookedEncoder.training"]], "training (transformer_lens.hookedtransformer.hookedtransformer attribute)": [[10, "transformer_lens.HookedTransformer.HookedTransformer.training"]], "training (transformer_lens.components.attention attribute)": [[10, "transformer_lens.components.Attention.training"]], "training (transformer_lens.components.bertblock attribute)": [[10, "transformer_lens.components.BertBlock.training"]], "training (transformer_lens.components.bertembed attribute)": [[10, "transformer_lens.components.BertEmbed.training"]], "training (transformer_lens.components.bertmlmhead attribute)": [[10, "transformer_lens.components.BertMLMHead.training"]], "training (transformer_lens.components.embed attribute)": [[10, "transformer_lens.components.Embed.training"]], "training (transformer_lens.components.gatedmlp attribute)": [[10, "transformer_lens.components.GatedMLP.training"]], "training (transformer_lens.components.layernorm attribute)": [[10, "transformer_lens.components.LayerNorm.training"]], "training (transformer_lens.components.layernormpre attribute)": [[10, "transformer_lens.components.LayerNormPre.training"]], "training (transformer_lens.components.mlp attribute)": [[10, "transformer_lens.components.MLP.training"]], "training (transformer_lens.components.posembed attribute)": [[10, "transformer_lens.components.PosEmbed.training"]], "training (transformer_lens.components.rmsnorm attribute)": [[10, "transformer_lens.components.RMSNorm.training"]], "training (transformer_lens.components.rmsnormpre attribute)": [[10, "transformer_lens.components.RMSNormPre.training"]], "training (transformer_lens.components.tokentypeembed attribute)": [[10, "transformer_lens.components.TokenTypeEmbed.training"]], "training (transformer_lens.components.transformerblock attribute)": [[10, "transformer_lens.components.TransformerBlock.training"]], "training (transformer_lens.components.unembed attribute)": [[10, "transformer_lens.components.Unembed.training"]], "training (transformer_lens.hook_points.hookpoint attribute)": [[10, "transformer_lens.hook_points.HookPoint.training"]], "training (transformer_lens.hook_points.hookedrootmodule attribute)": [[10, "transformer_lens.hook_points.HookedRootModule.training"]], "transformer_lens": [[10, "module-transformer_lens"]], "transformer_lens.activationcache": [[10, "module-transformer_lens.ActivationCache"]], "transformer_lens.factoredmatrix": [[10, "module-transformer_lens.FactoredMatrix"]], "transformer_lens.hookedencoder": [[10, "module-transformer_lens.HookedEncoder"]], "transformer_lens.hookedtransformer": [[10, "module-transformer_lens.HookedTransformer"]], "transformer_lens.hookedtransformerconfig": [[10, "module-transformer_lens.HookedTransformerConfig"]], "transformer_lens.components": [[10, "module-transformer_lens.components"]], "transformer_lens.evals": [[10, "module-transformer_lens.evals"]], "transformer_lens.head_detector": [[10, "module-transformer_lens.head_detector"]], "transformer_lens.hook_points": [[10, "module-transformer_lens.hook_points"]], "transformer_lens.loading_from_pretrained": [[10, "module-transformer_lens.loading_from_pretrained"]], "transformer_lens.make_docs": [[10, "module-transformer_lens.make_docs"]], "transformer_lens.past_key_value_caching": [[10, "module-transformer_lens.past_key_value_caching"]], "transformer_lens.patching": [[10, "module-transformer_lens.patching"]], "transformer_lens.train": [[10, "module-transformer_lens.train"]], "transformer_lens.utils": [[10, "module-transformer_lens.utils"]], "transpose() (in module transformer_lens.utils)": [[10, "transformer_lens.utils.transpose"]], "unsqueeze() (transformer_lens.factoredmatrix.factoredmatrix method)": [[10, "transformer_lens.FactoredMatrix.FactoredMatrix.unsqueeze"]], "use_attn_in (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_attn_in"]], "use_attn_result (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_attn_result"]], "use_attn_scale (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_attn_scale"]], "use_hook_mlp_in (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_hook_mlp_in"]], "use_hook_tokens (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_hook_tokens"]], "use_local_attn (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_local_attn"]], "use_split_qkv_input (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_split_qkv_input"]], "use_split_qkv_normalized_input (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.use_split_qkv_normalized_input"]], "values() (transformer_lens.activationcache.activationcache method)": [[10, "transformer_lens.ActivationCache.ActivationCache.values"]], "wandb (transformer_lens.train.hookedtransformertrainconfig attribute)": [[10, "transformer_lens.train.HookedTransformerTrainConfig.wandb"]], "wandb_project_name (transformer_lens.train.hookedtransformertrainconfig attribute)": [[10, "transformer_lens.train.HookedTransformerTrainConfig.wandb_project_name"]], "warmup_steps (transformer_lens.train.hookedtransformertrainconfig attribute)": [[10, "transformer_lens.train.HookedTransformerTrainConfig.warmup_steps"]], "weight_decay (transformer_lens.train.hookedtransformertrainconfig attribute)": [[10, "transformer_lens.train.HookedTransformerTrainConfig.weight_decay"]], "window_size (transformer_lens.hookedtransformerconfig.hookedtransformerconfig attribute)": [[10, "transformer_lens.HookedTransformerConfig.HookedTransformerConfig.window_size"]], "get_device_for_block_index() (in module transformer_lens.utilities.devices)": [[11, "transformer_lens.utilities.devices.get_device_for_block_index"]], "move_to_and_update_config() (in module transformer_lens.utilities.devices)": [[11, "transformer_lens.utilities.devices.move_to_and_update_config"]], "transformer_lens.utilities": [[11, "module-transformer_lens.utilities"]], "transformer_lens.utilities.devices": [[11, "module-transformer_lens.utilities.devices"]], "test() (in module typing_demo)": [[12, "typing_demo.test"]], "test2() (in module typing_demo)": [[12, "typing_demo.test2"]], "test3() (in module typing_demo)": [[12, "typing_demo.test3"]], "test4() (in module typing_demo)": [[12, "typing_demo.test4"]], "typing_demo": [[12, "module-typing_demo"]]}})